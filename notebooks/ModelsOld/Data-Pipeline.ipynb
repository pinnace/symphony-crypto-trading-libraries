{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras-tuner-1.0.1.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 476 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.43.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n",
      "Building wheels for collected packages: keras-tuner, terminaltables\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-py3-none-any.whl size=73198 sha256=5d920b8022b71500f3cd555fdedaa4008820cff55e1e9785b947911e90cdf56d\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/f0/c8/218919df808b66696bdb2fbc2261ae74412383483226b0b31d\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=4d65d4dff5c926ef66ebf2fa844dca1dc2b1d882f91b31022db841bbb5fa8d27\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/1b/58/c23af2fe683acd8edc15d5a1268f0242be1ff2cf827fe34737\n",
      "Successfully built keras-tuner terminaltables\n",
      "Installing collected packages: tabulate, terminaltables, colorama, keras-tuner\n",
      "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 tabulate-0.8.7 terminaltables-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.metrics import AUC, binary_accuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = [\n",
    "    \"../demarkindicators/backtest/backtests/results/test_results/EURUSD/ALL/EURUSD60/\",\n",
    "    \"../demarkindicators/backtest/backtests/results/test_results/EURGBP/ALL/EURGBP60/\"\n",
    "    \"../demarkindicators/backtest/backtests/results/test_results/AUDUSD/ALL/AUDUSD60/\",\n",
    "    \"../demarkindicators/backtest/backtests/results/test_results/GBPUSD/ALL/GBPUSD60/\",\n",
    "    \"../demarkindicators/backtest/backtests/results/test_results/USDCAD/ALL/USDCAD60/\",\n",
    "    \"../demarkindicators/backtest/backtests/results/test_results/USDCHF/ALL/USDCHF60/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id_list = [\n",
    "        (os.path.dirname(filename), int(os.path.basename(filename).split(\".\")[0]))\n",
    "        for test_dir in test_dirs\n",
    "        for filename in glob.glob(test_dir + \"*.csv\") \n",
    "        \n",
    "    ]\n",
    "file_id_list = sorted(file_id_list, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files, label_files = [], []\n",
    "\n",
    "for path, file_id in file_id_list:\n",
    "    data_files.append(os.path.join(path, str(file_id)) + \".csv\")\n",
    "    label_files.append(os.path.join(path, str(file_id)) + \".meta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../demarkindicators/backtest/backtests/results/test_results/EURUSD/ALL/EURUSD60/1420588800.csv\n",
      "../demarkindicators/backtest/backtests/results/test_results/EURUSD/ALL/EURUSD60/1420588800.meta\n"
     ]
    }
   ],
   "source": [
    "print(data_files[0])\n",
    "print(label_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data = []\n",
    "#for i,datafile in enumerate(data_files):\n",
    "#    data = np.genfromtxt(datafile, delimiter=',',skip_header=1 )\n",
    "#    input_data.append(data)\n",
    "\n",
    "input_data = []\n",
    "for i,datafile in enumerate(data_files):\n",
    "    data = np.genfromtxt(datafile, delimiter=',',skip_header=1 )\n",
    "    input_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profitable</th>\n",
       "      <th>profit_in_pips</th>\n",
       "      <th>instrument</th>\n",
       "      <th>order_type</th>\n",
       "      <th>time</th>\n",
       "      <th>posix_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1758</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>BUY</td>\n",
       "      <td>2015-01-07 00:00:00</td>\n",
       "      <td>1420588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-165</td>\n",
       "      <td>USDCAD</td>\n",
       "      <td>SELL</td>\n",
       "      <td>2015-01-07 00:00:00</td>\n",
       "      <td>1420588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-482</td>\n",
       "      <td>USDCHF</td>\n",
       "      <td>SELL</td>\n",
       "      <td>2015-01-07 00:00:00</td>\n",
       "      <td>1420588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-676</td>\n",
       "      <td>GBPUSD</td>\n",
       "      <td>BUY</td>\n",
       "      <td>2015-01-08 00:00:00</td>\n",
       "      <td>1420675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-442</td>\n",
       "      <td>USDCAD</td>\n",
       "      <td>SELL</td>\n",
       "      <td>2015-01-09 00:00:00</td>\n",
       "      <td>1420761600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profitable  profit_in_pips instrument order_type                 time  \\\n",
       "0           0           -1758     EURUSD        BUY  2015-01-07 00:00:00   \n",
       "1           0            -165     USDCAD       SELL  2015-01-07 00:00:00   \n",
       "2           0            -482     USDCHF       SELL  2015-01-07 00:00:00   \n",
       "3           0            -676     GBPUSD        BUY  2015-01-08 00:00:00   \n",
       "4           0            -442     USDCAD       SELL  2015-01-09 00:00:00   \n",
       "\n",
       "   posix_time  \n",
       "0  1420588800  \n",
       "1  1420588800  \n",
       "2  1420588800  \n",
       "3  1420675200  \n",
       "4  1420761600  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [pd.read_csv(filename) for filename in label_files]\n",
    "all_labels = pd.concat(df_list, ignore_index=True)\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_indices = all_labels.index[all_labels['order_type'] == \"BUY\"].tolist()\n",
    "sell_indices = all_labels.index[all_labels['order_type'] == \"SELL\"].tolist()\n",
    "buy_labels = all_labels.loc[all_labels['order_type'] == \"BUY\"][\"profitable\"].values\n",
    "sell_labels = all_labels.loc[all_labels['order_type'] == \"SELL\"][\"profitable\"].values\n",
    "buy_profits = all_labels.loc[all_labels['order_type'] == \"BUY\"][\"profit_in_pips\"].values\n",
    "sell_profits = all_labels.loc[all_labels['order_type'] == \"SELL\"][\"profit_in_pips\"].values\n",
    "buy_inputs = [input_data[i] for i in buy_indices]\n",
    "sell_inputs = [input_data[i] for i in sell_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Profitable BUY: 0.342911877394636\n",
      "% Profitable SELL: 0.2564102564102564\n"
     ]
    }
   ],
   "source": [
    "print(\"% Profitable BUY: {}\".format(list(buy_labels).count(1) / len(buy_labels)))\n",
    "print(\"% Profitable SELL: {}\".format(list(sell_labels).count(1) / len(sell_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNaN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, inputs):\n",
    "        for a in inputs:\n",
    "            nan_locations = np.isnan(a)\n",
    "            a[nan_locations] = 0.0\n",
    "        return inputs\n",
    "\n",
    "    def fit(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, inputs):\n",
    "        scaler = MinMaxScaler(feature_range=(0.0001, 1.0))\n",
    "        inputs = list(map(lambda inp: scaler.fit_transform(inp), inputs))\n",
    "        return inputs\n",
    "\n",
    "    def fit(self, inputs):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transposer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, inputs):\n",
    "        inputs = list(map(lambda inp: inp.T, inputs))\n",
    "        return inputs\n",
    "\n",
    "    def fit(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroPad(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, inputs):\n",
    "        max_len = 0\n",
    "        for inpd in inputs:\n",
    "            if len(inpd[0]) > max_len:\n",
    "                max_len = len(inpd[0])\n",
    "        inputs = list(map(lambda inp: sequence.pad_sequences(inp, dtype='float32', maxlen=max_len, padding='post'), inputs))\n",
    "        return inputs\n",
    "\n",
    "    def fit(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numpy3D(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, inputs):\n",
    "        return np.array(inputs)\n",
    "\n",
    "    def fit(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "            steps=\n",
    "            [\n",
    "                ('fill_nan', FillNaN()),\n",
    "                ('min_max',MinMaxer()),\n",
    "                #('transpose', Transposer()),\n",
    "                ('zero_pad',ZeroPad()),\n",
    "                ('numpy_3d', Numpy3D())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_data_pipelined = pipe.transform(buy_inputs)\n",
    "sell_data_pipelined = pipe.transform(sell_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adopt a different train test split strategy that doubles as forward testing.\n",
    "# -> Find the index whereat 80% of the trades lies before, use that as training.\n",
    "\n",
    "train_perc = 0.8\n",
    "buy_stop_index = round(len(buy_labels) * train_perc)\n",
    "X_buy_train = buy_data_pipelined[:buy_stop_index]\n",
    "X_buy_test = buy_data_pipelined[buy_stop_index:]\n",
    "y_buy_train = buy_labels[:buy_stop_index]\n",
    "y_buy_test = buy_labels[buy_stop_index:]\n",
    "profit_buy_train = buy_profits[:buy_stop_index]\n",
    "profit_buy_test = buy_profits[buy_stop_index:]\n",
    "\n",
    "\n",
    "sell_stop_index = round(len(sell_labels) * train_perc)\n",
    "X_sell_train = sell_data_pipelined[:sell_stop_index]\n",
    "X_sell_test = sell_data_pipelined[sell_stop_index:]\n",
    "y_sell_train = sell_labels[:sell_stop_index]\n",
    "y_sell_test = sell_labels[sell_stop_index:]\n",
    "profit_sell_train = buy_profits[:sell_stop_index]\n",
    "profit_sell_test = buy_profits[sell_stop_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "print(X_buy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-c5e76f3d53f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_buy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_buy_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(model, X_test: list, y_test: list, profits: list, verbose=True, threshold=0.5) -> tuple:\n",
    "    true_positives, true_negatives, false_positives, false_negatives = 0, 0, 0, 0\n",
    "    positives, negatives = list(y_test).count(1), list(y_test).count(0)\n",
    "    \n",
    "    print(\"Analyzing {} samples\".format(len(y_test)))\n",
    "    print(\"Threshold: {}\".format(threshold))\n",
    "    profit = 0\n",
    "    for i, (inp, label) in enumerate(zip(X_test, y_test)):\n",
    "        inp = inp.reshape(1, X_test.shape[1], X_test.shape[2])\n",
    "        prob_prediction = model.predict([inp], batch_size=1)[0][0]\n",
    "        class_prediction = model.predict_classes([inp], batch_size=1)[0][0]\n",
    "        \n",
    "        \n",
    "        is_predicted_profitable = True if prob_prediction > threshold else False\n",
    "        \n",
    "        if is_predicted_profitable:\n",
    "            print(\"Profit: {}\".format(profits[i]))\n",
    "            profit += profits[i]\n",
    "        \n",
    "        \n",
    "        if is_predicted_profitable and label:\n",
    "            true_positives += 1\n",
    "        elif not is_predicted_profitable and not label:\n",
    "            true_negatives += 1\n",
    "        elif is_predicted_profitable and not label:\n",
    "            false_positives += 1\n",
    "        elif not is_predicted_profitable and label:\n",
    "            false_negatives += 1\n",
    "            print(\"False Negative, prob: {}\".format(prob_prediction))\n",
    "        else:\n",
    "            raise Exception(\"Error!\")\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    if verbose:\n",
    "        print(\"The model guessed:\")\n",
    "        print(\"\\t{}/{} profitable trades correctly (true positives)\".format(true_positives, positives))\n",
    "        print(\"\\t{}/{} profitable trades incorrectly (false negatives)\".format(false_negatives, positives))\n",
    "        print(\"\\t{}/{} unprofitable trades correctly (true negatives)\".format(true_negatives, negatives))\n",
    "        print(\"\\t{}/{} unprofitable trades incorrectly (false positives)\".format(false_positives, negatives))\n",
    "        print(\"\\t Precision: {}\".format(precision))\n",
    "        print(\"\\t Recall: {}\".format(recall))\n",
    "        print(\"\\t Profit: {}\".format(profit))\n",
    "    return (precision, recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning for Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), \n",
    "                   return_sequences=True, input_shape=(X_buy_train.shape[1], X_buy_train.shape[2]), dropout=0.2, recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=hp.Int('units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), \n",
    "                   return_sequences=True))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=hp.Int('units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(\n",
    "                                hp.Choice('learning_rate',\n",
    "                                  values=[1e-2, 1e-3, 1e-4])), \n",
    "                  metrics=[binary_accuracy])\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 51s - loss: 0.6819 - binary_accuracy: 0.65 - ETA: 23s - loss: 0.6778 - binary_accuracy: 0.62 - ETA: 14s - loss: 0.6708 - binary_accuracy: 0.62 - ETA: 9s - loss: 0.6641 - binary_accuracy: 0.6484 - ETA: 6s - loss: 0.6636 - binary_accuracy: 0.650 - ETA: 4s - loss: 0.6667 - binary_accuracy: 0.640 - ETA: 3s - loss: 0.6693 - binary_accuracy: 0.638 - ETA: 1s - loss: 0.6609 - binary_accuracy: 0.648 - ETA: 1s - loss: 0.6590 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6532 - binary_accuracy: 0.668 - 6s 19ms/sample - loss: 0.6496 - binary_accuracy: 0.6726\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7308 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6928 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6468 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6483 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6673 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6531 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6238 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.671 - 1s 3ms/sample - loss: 0.6149 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5187 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5717 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5788 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5975 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5950 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6104 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6175 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6137 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5425 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5632 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5673 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5808 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5845 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5834 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5881 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6121 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6426 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6396 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6065 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6075 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6147 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6101 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6053 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5819 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5898 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6078 - binary_accuracy: 0.6873\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5298 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5748 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5592 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5700 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5640 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5755 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5744 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5772 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6001 - binary_accuracy: 0.6962\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5806 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5944 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.5997 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.5967 - binary_accuracy: 0.6932\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5727 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6149 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6057 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6784 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6469 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5874 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5881 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5986 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6008 - binary_accuracy: 0.6873\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5911 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5516 - binary_accuracy: 0.757 - ETA: 0s - loss: 0.5602 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5434 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5710 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5704 - binary_accuracy: 0.730 - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6015 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6416 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6218 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6165 - binary_accuracy: 0.668 - 1s 3ms/sample - loss: 0.6071 - binary_accuracy: 0.6814\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 47s - loss: 0.7270 - binary_accuracy: 0.37 - ETA: 21s - loss: 0.7156 - binary_accuracy: 0.43 - ETA: 12s - loss: 0.7090 - binary_accuracy: 0.47 - ETA: 8s - loss: 0.6969 - binary_accuracy: 0.5234 - ETA: 5s - loss: 0.6910 - binary_accuracy: 0.550 - ETA: 4s - loss: 0.6847 - binary_accuracy: 0.572 - ETA: 2s - loss: 0.6726 - binary_accuracy: 0.602 - ETA: 1s - loss: 0.6710 - binary_accuracy: 0.605 - ETA: 0s - loss: 0.6705 - binary_accuracy: 0.607 - ETA: 0s - loss: 0.6641 - binary_accuracy: 0.615 - 6s 17ms/sample - loss: 0.6661 - binary_accuracy: 0.6165\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5040 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5822 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6100 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6274 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6148 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6343 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6345 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6890 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6726 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6433 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6643 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6758 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6566 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6392 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6362 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6292 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6207 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7358 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6384 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6281 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6130 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6097 - binary_accuracy: 0.6873\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6848 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6366 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6104 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6038 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6105 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5455 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5276 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5821 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5647 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5481 - binary_accuracy: 0.744 - ETA: 0s - loss: 0.5479 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5594 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5846 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5922 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5574 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6148 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6369 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5958 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5878 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6037 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6495 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6721 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6681 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6186 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6107 - binary_accuracy: 0.6785\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6129 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5639 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6243 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.5954 - binary_accuracy: 0.6962\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5897 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6056 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5950 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5949 - binary_accuracy: 0.6962\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5772 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.6168 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6146 - binary_accuracy: 0.6991\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6547 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6244 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6291 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6164 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6180 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6027 - binary_accuracy: 0.6932\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 1:05 - loss: 0.7291 - binary_accuracy: 0.312 - ETA: 29s - loss: 0.7140 - binary_accuracy: 0.375 - ETA: 17s - loss: 0.7155 - binary_accuracy: 0.37 - ETA: 11s - loss: 0.7058 - binary_accuracy: 0.42 - ETA: 7s - loss: 0.6953 - binary_accuracy: 0.4938 - ETA: 5s - loss: 0.6860 - binary_accuracy: 0.520 - ETA: 3s - loss: 0.6816 - binary_accuracy: 0.540 - ETA: 2s - loss: 0.6829 - binary_accuracy: 0.543 - ETA: 1s - loss: 0.6737 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6679 - binary_accuracy: 0.578 - 8s 23ms/sample - loss: 0.6651 - binary_accuracy: 0.5841\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6863 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6690 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6367 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6550 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6325 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6078 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.5351 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6136 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6082 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7807 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6946 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6159 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6124 - binary_accuracy: 0.6814\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5596 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5561 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5884 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5977 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6150 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6079 - binary_accuracy: 0.6814\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6577 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6415 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6516 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6348 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6130 - binary_accuracy: 0.6932\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5874 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6066 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6119 - binary_accuracy: 0.6962\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5835 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.7100 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6576 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5849 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5842 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6000 - binary_accuracy: 0.6873\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6762 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6484 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6015 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5980 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5849 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5977 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5852 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5782 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.6055 - binary_accuracy: 0.6903\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5752 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5773 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6153 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6283 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.5968 - binary_accuracy: 0.7080\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5808 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6071 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6356 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6100 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6051 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6046 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1aef3aae13184f5ed96e1ea0ae69313a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7010815739631653</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 1:06 - loss: 0.7157 - binary_accuracy: 0.468 - ETA: 30s - loss: 0.7043 - binary_accuracy: 0.515 - ETA: 18s - loss: 0.6930 - binary_accuracy: 0.54 - ETA: 11s - loss: 0.6883 - binary_accuracy: 0.55 - ETA: 8s - loss: 0.6824 - binary_accuracy: 0.5750 - ETA: 5s - loss: 0.6810 - binary_accuracy: 0.583 - ETA: 3s - loss: 0.6846 - binary_accuracy: 0.575 - ETA: 2s - loss: 0.6663 - binary_accuracy: 0.617 - ETA: 1s - loss: 0.6646 - binary_accuracy: 0.618 - ETA: 0s - loss: 0.6605 - binary_accuracy: 0.625 - 8s 25ms/sample - loss: 0.6578 - binary_accuracy: 0.6283\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6401 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6350 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6115 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6386 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6370 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6425 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6211 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.4785 - binary_accuracy: 0.843 - ETA: 1s - loss: 0.5582 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5447 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5784 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6012 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.6164 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6828 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6333 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6175 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.703 - 1s 4ms/sample - loss: 0.6144 - binary_accuracy: 0.6932\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6074 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6109 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5750 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5874 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.684 - 1s 4ms/sample - loss: 0.6130 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6419 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6273 - binary_accuracy: 0.671 - ETA: 1s - loss: 0.5888 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6062 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5962 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.693 - 1s 4ms/sample - loss: 0.6065 - binary_accuracy: 0.6873\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6071 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6326 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6335 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.675 - 1s 4ms/sample - loss: 0.6043 - binary_accuracy: 0.6873\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6122 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6556 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6267 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.700 - 1s 4ms/sample - loss: 0.5957 - binary_accuracy: 0.7050\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.4916 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.4949 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5569 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5510 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5614 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5760 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5841 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5981 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5977 - binary_accuracy: 0.690 - 1s 4ms/sample - loss: 0.6022 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6134 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6076 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5842 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6147 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5871 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.684 - 1s 4ms/sample - loss: 0.5999 - binary_accuracy: 0.6873\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5183 - binary_accuracy: 0.812 - ETA: 1s - loss: 0.5622 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5787 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6066 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6049 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.6027 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5837 - binary_accuracy: 0.750 - ETA: 1s - loss: 0.5982 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.6108 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6106 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5957 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6249 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6153 - binary_accuracy: 0.659 - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.681 - 2s 5ms/sample - loss: 0.6028 - binary_accuracy: 0.6814\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 1:29 - loss: 0.6816 - binary_accuracy: 0.687 - ETA: 40s - loss: 0.6814 - binary_accuracy: 0.593 - ETA: 24s - loss: 0.6752 - binary_accuracy: 0.62 - ETA: 16s - loss: 0.6824 - binary_accuracy: 0.58 - ETA: 11s - loss: 0.6795 - binary_accuracy: 0.60 - ETA: 7s - loss: 0.6763 - binary_accuracy: 0.6042 - ETA: 5s - loss: 0.6634 - binary_accuracy: 0.638 - ETA: 3s - loss: 0.6541 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6506 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6407 - binary_accuracy: 0.675 - 11s 32ms/sample - loss: 0.6393 - binary_accuracy: 0.6726\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6600 - binary_accuracy: 0.625 - ETA: 1s - loss: 0.5798 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.6323 - binary_accuracy: 0.666 - ETA: 1s - loss: 0.6277 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6244 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6251 - binary_accuracy: 0.675 - 2s 5ms/sample - loss: 0.6183 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.7049 - binary_accuracy: 0.593 - ETA: 1s - loss: 0.6316 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6069 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6237 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6048 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6063 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6048 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.678 - 2s 5ms/sample - loss: 0.6044 - binary_accuracy: 0.6873\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.4983 - binary_accuracy: 0.812 - ETA: 1s - loss: 0.5062 - binary_accuracy: 0.796 - ETA: 1s - loss: 0.5306 - binary_accuracy: 0.760 - ETA: 1s - loss: 0.5618 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5723 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.693 - 2s 5ms/sample - loss: 0.6143 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6314 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.5958 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.5587 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5831 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5863 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5915 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5876 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5950 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5947 - binary_accuracy: 0.700 - 2s 5ms/sample - loss: 0.5999 - binary_accuracy: 0.6962\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5441 - binary_accuracy: 0.781 - ETA: 1s - loss: 0.5986 - binary_accuracy: 0.734 - ETA: 1s - loss: 0.5856 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5704 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5870 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5888 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5875 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5911 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.700 - 1s 4ms/sample - loss: 0.6007 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6082 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6406 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6655 - binary_accuracy: 0.625 - ETA: 1s - loss: 0.6484 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6141 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6185 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.681 - 2s 5ms/sample - loss: 0.6043 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6509 - binary_accuracy: 0.625 - ETA: 1s - loss: 0.6255 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6486 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6242 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.700 - 2s 5ms/sample - loss: 0.5931 - binary_accuracy: 0.7021\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5738 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6067 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.5821 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5677 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6004 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6007 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6007 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5274 - binary_accuracy: 0.750 - ETA: 1s - loss: 0.5648 - binary_accuracy: 0.703 - ETA: 1s - loss: 0.5940 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5930 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6299 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6001 - binary_accuracy: 0.6873\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5639 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.6115 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6070 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5869 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5785 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5943 - binary_accuracy: 0.703 - 1s 4ms/sample - loss: 0.5999 - binary_accuracy: 0.6932\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5529 - binary_accuracy: 0.750 - ETA: 1s - loss: 0.6217 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.703 - 1s 4ms/sample - loss: 0.6004 - binary_accuracy: 0.6962\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 54s - loss: 0.7157 - binary_accuracy: 0.43 - ETA: 24s - loss: 0.7011 - binary_accuracy: 0.48 - ETA: 14s - loss: 0.6808 - binary_accuracy: 0.56 - ETA: 9s - loss: 0.6793 - binary_accuracy: 0.5781 - ETA: 6s - loss: 0.6788 - binary_accuracy: 0.593 - ETA: 4s - loss: 0.6591 - binary_accuracy: 0.640 - ETA: 3s - loss: 0.6555 - binary_accuracy: 0.647 - ETA: 2s - loss: 0.6545 - binary_accuracy: 0.644 - ETA: 1s - loss: 0.6601 - binary_accuracy: 0.628 - ETA: 0s - loss: 0.6483 - binary_accuracy: 0.646 - 7s 20ms/sample - loss: 0.6490 - binary_accuracy: 0.6460\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5864 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6364 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.6192 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 1s - loss: 0.4648 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5409 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6455 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6413 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6137 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5527 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5759 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6094 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6021 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6035 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5561 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5667 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5794 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5706 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6101 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6071 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.700 - 1s 4ms/sample - loss: 0.6014 - binary_accuracy: 0.7021\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6932 - binary_accuracy: 0.593 - ETA: 1s - loss: 0.6477 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6094 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6100 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.5965 - binary_accuracy: 0.6814\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5920 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5885 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5770 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5785 - binary_accuracy: 0.730 - ETA: 0s - loss: 0.5844 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5850 - binary_accuracy: 0.712 - 1s 4ms/sample - loss: 0.5911 - binary_accuracy: 0.7080\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6049 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5444 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5716 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5769 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5815 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6025 - binary_accuracy: 0.6873\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6174 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5665 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5744 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5712 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5756 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5753 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5808 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5901 - binary_accuracy: 0.709 - 1s 4ms/sample - loss: 0.5941 - binary_accuracy: 0.7021\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5696 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6360 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6165 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.703 - 1s 4ms/sample - loss: 0.5927 - binary_accuracy: 0.7109\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5587 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5868 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.5947 - binary_accuracy: 0.690 - 1s 4ms/sample - loss: 0.5902 - binary_accuracy: 0.6962\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5797 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5317 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5434 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5346 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5695 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5832 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5823 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5950 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6063 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5912 - binary_accuracy: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 0b4b056a342d5badf1e787bd85b6b93a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7059980034828186</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 55s - loss: 0.6766 - binary_accuracy: 0.65 - ETA: 14s - loss: 0.6951 - binary_accuracy: 0.48 - ETA: 6s - loss: 0.6981 - binary_accuracy: 0.4563 - ETA: 4s - loss: 0.6971 - binary_accuracy: 0.474 - ETA: 3s - loss: 0.6975 - binary_accuracy: 0.464 - ETA: 1s - loss: 0.6979 - binary_accuracy: 0.453 - ETA: 0s - loss: 0.6984 - binary_accuracy: 0.453 - 6s 19ms/sample - loss: 0.6985 - binary_accuracy: 0.4543\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6796 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6878 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6878 - binary_accuracy: 0.570 - ETA: 0s - loss: 0.6886 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6877 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6853 - binary_accuracy: 0.572 - 1s 2ms/sample - loss: 0.6865 - binary_accuracy: 0.5664\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6714 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6771 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6810 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6863 - binary_accuracy: 0.588 - ETA: 0s - loss: 0.6881 - binary_accuracy: 0.567 - ETA: 0s - loss: 0.6864 - binary_accuracy: 0.574 - ETA: 0s - loss: 0.6854 - binary_accuracy: 0.578 - 1s 2ms/sample - loss: 0.6858 - binary_accuracy: 0.5752\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6715 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6673 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6663 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6689 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6695 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6744 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6723 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6697 - binary_accuracy: 0.628 - ETA: 0s - loss: 0.6695 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6712 - binary_accuracy: 0.621 - 1s 2ms/sample - loss: 0.6689 - binary_accuracy: 0.6313\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6527 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6511 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6431 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6403 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6417 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6504 - binary_accuracy: 0.659 - 1s 2ms/sample - loss: 0.6521 - binary_accuracy: 0.6608\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6586 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6598 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6446 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6532 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6565 - binary_accuracy: 0.666 - 1s 2ms/sample - loss: 0.6558 - binary_accuracy: 0.6726\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6498 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6603 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6424 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6525 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6505 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6540 - binary_accuracy: 0.665 - 1s 2ms/sample - loss: 0.6529 - binary_accuracy: 0.6696\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6767 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6415 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6291 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.6429 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6434 - binary_accuracy: 0.687 - 0s 1ms/sample - loss: 0.6426 - binary_accuracy: 0.6932\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6379 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6212 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6619 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6600 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6492 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.663 - 1s 2ms/sample - loss: 0.6367 - binary_accuracy: 0.6785\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6302 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6233 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6367 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6423 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6401 - binary_accuracy: 0.6785\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6516 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6464 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6458 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6468 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6343 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6316 - binary_accuracy: 0.6785\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7129 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.6387 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6292 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6281 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.701 - 1s 2ms/sample - loss: 0.6272 - binary_accuracy: 0.6873\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 47s - loss: 0.7109 - binary_accuracy: 0.40 - ETA: 12s - loss: 0.7191 - binary_accuracy: 0.39 - ETA: 5s - loss: 0.7133 - binary_accuracy: 0.4062 - ETA: 2s - loss: 0.7115 - binary_accuracy: 0.419 - ETA: 1s - loss: 0.7087 - binary_accuracy: 0.437 - ETA: 0s - loss: 0.7070 - binary_accuracy: 0.454 - 5s 16ms/sample - loss: 0.7042 - binary_accuracy: 0.4720\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6979 - binary_accuracy: 0.375 - ETA: 0s - loss: 0.6953 - binary_accuracy: 0.458 - ETA: 0s - loss: 0.6893 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6884 - binary_accuracy: 0.493 - ETA: 0s - loss: 0.6810 - binary_accuracy: 0.540 - ETA: 0s - loss: 0.6808 - binary_accuracy: 0.559 - 0s 1ms/sample - loss: 0.6813 - binary_accuracy: 0.5634\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6654 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6694 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6645 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6633 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6610 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6644 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6666 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6677 - binary_accuracy: 0.653 - 1s 2ms/sample - loss: 0.6676 - binary_accuracy: 0.6549\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6707 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6615 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6574 - binary_accuracy: 0.666 - 0s 1ms/sample - loss: 0.6560 - binary_accuracy: 0.6726\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6575 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6513 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6409 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6484 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6557 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6487 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6475 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6468 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6099 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6222 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6386 - binary_accuracy: 0.6814\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6572 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6475 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6359 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6249 - binary_accuracy: 0.687 - 1s 1ms/sample - loss: 0.6263 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5788 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6291 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6204 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6138 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.671 - 0s 1ms/sample - loss: 0.6232 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6570 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6375 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6149 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6311 - binary_accuracy: 0.681 - 0s 1ms/sample - loss: 0.6276 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6754 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6607 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6413 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6359 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6284 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7323 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6987 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6859 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6623 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6579 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6501 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6360 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6437 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6295 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5911 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6243 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6286 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6458 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6377 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6456 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6401 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6298 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 55s - loss: 0.7038 - binary_accuracy: 0.43 - ETA: 14s - loss: 0.7179 - binary_accuracy: 0.44 - ETA: 6s - loss: 0.7190 - binary_accuracy: 0.3750 - ETA: 3s - loss: 0.7149 - binary_accuracy: 0.392 - ETA: 1s - loss: 0.7143 - binary_accuracy: 0.402 - 6s 18ms/sample - loss: 0.7136 - binary_accuracy: 0.4130\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6902 - binary_accuracy: 0.468 - ETA: 0s - loss: 0.7032 - binary_accuracy: 0.406 - ETA: 0s - loss: 0.7026 - binary_accuracy: 0.414 - ETA: 0s - loss: 0.6975 - binary_accuracy: 0.450 - ETA: 0s - loss: 0.6983 - binary_accuracy: 0.458 - ETA: 0s - loss: 0.6958 - binary_accuracy: 0.476 - ETA: 0s - loss: 0.6953 - binary_accuracy: 0.479 - 1s 2ms/sample - loss: 0.6957 - binary_accuracy: 0.4897\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6735 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6828 - binary_accuracy: 0.552 - ETA: 0s - loss: 0.6858 - binary_accuracy: 0.554 - ETA: 0s - loss: 0.6885 - binary_accuracy: 0.537 - ETA: 0s - loss: 0.6835 - binary_accuracy: 0.567 - ETA: 0s - loss: 0.6832 - binary_accuracy: 0.582 - ETA: 0s - loss: 0.6822 - binary_accuracy: 0.596 - 1s 2ms/sample - loss: 0.6808 - binary_accuracy: 0.6018\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6855 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6668 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6695 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6714 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6692 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6676 - binary_accuracy: 0.649 - ETA: 0s - loss: 0.6700 - binary_accuracy: 0.637 - 1s 2ms/sample - loss: 0.6692 - binary_accuracy: 0.6401\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6555 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6715 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6625 - binary_accuracy: 0.618 - ETA: 0s - loss: 0.6669 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6584 - binary_accuracy: 0.649 - ETA: 0s - loss: 0.6599 - binary_accuracy: 0.646 - 0s 1ms/sample - loss: 0.6609 - binary_accuracy: 0.6431\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6664 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6546 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6488 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6573 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6628 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6631 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6566 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6563 - binary_accuracy: 0.6785\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6477 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6441 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6472 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6522 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6513 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6520 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6562 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6525 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6540 - binary_accuracy: 0.6696\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6380 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6575 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6443 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6382 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6364 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6362 - binary_accuracy: 0.6696\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5405 - binary_accuracy: 0.875 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6313 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6329 - binary_accuracy: 0.687 - 0s 1ms/sample - loss: 0.6370 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6311 - binary_accuracy: 0.6814\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7125 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6346 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6266 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6303 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6304 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5837 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6212 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6226 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2b7a5ca13e9a739021899e2d60374990</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6892821788787842</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 53s - loss: 0.7128 - binary_accuracy: 0.37 - ETA: 24s - loss: 0.6718 - binary_accuracy: 0.56 - ETA: 14s - loss: 0.6546 - binary_accuracy: 0.59 - ETA: 9s - loss: 0.6468 - binary_accuracy: 0.6172 - ETA: 6s - loss: 0.6707 - binary_accuracy: 0.606 - ETA: 4s - loss: 0.6665 - binary_accuracy: 0.614 - ETA: 1s - loss: 0.6506 - binary_accuracy: 0.632 - ETA: 1s - loss: 0.6426 - binary_accuracy: 0.649 - ETA: 0s - loss: 0.6381 - binary_accuracy: 0.656 - 6s 18ms/sample - loss: 0.6447 - binary_accuracy: 0.6490\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6401 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6391 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6208 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6170 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5357 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5964 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5905 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5964 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.700 - 1s 2ms/sample - loss: 0.6070 - binary_accuracy: 0.6991\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6630 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5975 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5937 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5900 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5862 - binary_accuracy: 0.730 - ETA: 0s - loss: 0.5812 - binary_accuracy: 0.732 - 1s 2ms/sample - loss: 0.5859 - binary_accuracy: 0.7198\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6380 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5676 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5824 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6063 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.708 - 1s 2ms/sample - loss: 0.6052 - binary_accuracy: 0.6903\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5396 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5879 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5815 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5811 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5894 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.5948 - binary_accuracy: 0.6903\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6039 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6251 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6275 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6254 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6335 - binary_accuracy: 0.650 - 1s 2ms/sample - loss: 0.6435 - binary_accuracy: 0.6431\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7125 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6752 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6789 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6704 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6352 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.701 - 1s 2ms/sample - loss: 0.6047 - binary_accuracy: 0.7021\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6564 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.5533 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5949 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5729 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.5980 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.5905 - binary_accuracy: 0.6962\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5385 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5617 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5906 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5849 - binary_accuracy: 0.718 - 1s 2ms/sample - loss: 0.5849 - binary_accuracy: 0.7139\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5159 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5241 - binary_accuracy: 0.828 - ETA: 0s - loss: 0.5357 - binary_accuracy: 0.770 - ETA: 0s - loss: 0.5198 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5550 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.738 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.736 - ETA: 0s - loss: 0.5803 - binary_accuracy: 0.731 - 1s 2ms/sample - loss: 0.5753 - binary_accuracy: 0.7345\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5301 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6349 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6170 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5799 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5910 - binary_accuracy: 0.715 - 1s 2ms/sample - loss: 0.5851 - binary_accuracy: 0.7168\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 52s - loss: 0.7042 - binary_accuracy: 0.50 - ETA: 23s - loss: 0.6869 - binary_accuracy: 0.54 - ETA: 13s - loss: 0.6719 - binary_accuracy: 0.58 - ETA: 6s - loss: 0.6482 - binary_accuracy: 0.6375 - ETA: 2s - loss: 0.6374 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6419 - binary_accuracy: 0.652 - ETA: 1s - loss: 0.6275 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.671 - 6s 17ms/sample - loss: 0.6292 - binary_accuracy: 0.6696\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5351 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.4796 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5259 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5639 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5793 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5789 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5938 - binary_accuracy: 0.704 - 1s 2ms/sample - loss: 0.5980 - binary_accuracy: 0.6962\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5774 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6161 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6100 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6159 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6096 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6032 - binary_accuracy: 0.6962\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5946 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6160 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6100 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6020 - binary_accuracy: 0.7021\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5645 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6117 - binary_accuracy: 0.6962\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6581 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5943 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.662 - 1s 1ms/sample - loss: 0.6069 - binary_accuracy: 0.6696\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5617 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5862 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5951 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.697 - 1s 2ms/sample - loss: 0.5948 - binary_accuracy: 0.6962\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5301 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5911 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5873 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5936 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.680 - 1s 2ms/sample - loss: 0.5899 - binary_accuracy: 0.6903\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6391 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6379 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.701 - 1s 2ms/sample - loss: 0.5981 - binary_accuracy: 0.7080\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5530 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5279 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5956 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5566 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5932 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5958 - binary_accuracy: 0.700 - 1s 1ms/sample - loss: 0.5933 - binary_accuracy: 0.7050\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5860 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.700 - 1s 1ms/sample - loss: 0.6037 - binary_accuracy: 0.6962\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6850 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6593 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6068 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.5979 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 50s - loss: 0.6794 - binary_accuracy: 0.71 - ETA: 13s - loss: 0.6533 - binary_accuracy: 0.67 - ETA: 6s - loss: 0.6374 - binary_accuracy: 0.6875 - ETA: 2s - loss: 0.6351 - binary_accuracy: 0.683 - ETA: 1s - loss: 0.6336 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.670 - 6s 17ms/sample - loss: 0.6370 - binary_accuracy: 0.6726\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6229 - binary_accuracy: 0.678 - 1s 1ms/sample - loss: 0.6228 - binary_accuracy: 0.6785\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5741 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6075 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6071 - binary_accuracy: 0.6962\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6211 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5950 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5975 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6111 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6155 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6643 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5964 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5753 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6120 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4968 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5392 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5758 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5786 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5848 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5891 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.5882 - binary_accuracy: 0.7021\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6167 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.5881 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5770 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5943 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6070 - binary_accuracy: 0.6873\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5179 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6248 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6153 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6059 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.6016 - binary_accuracy: 0.6991\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6170 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.697 - 1s 2ms/sample - loss: 0.5886 - binary_accuracy: 0.7050\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4839 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6241 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.697 - 1s 2ms/sample - loss: 0.5948 - binary_accuracy: 0.7050\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5643 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5750 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5777 - binary_accuracy: 0.712 - 1s 2ms/sample - loss: 0.5730 - binary_accuracy: 0.7198\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 1s - loss: 0.5829 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5657 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5570 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5592 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5749 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5754 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5882 - binary_accuracy: 0.721 - 1s 2ms/sample - loss: 0.5875 - binary_accuracy: 0.7168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9cd8274ff80d741bd254c1b217e444f9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7207472920417786</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 49s - loss: 0.6932 - binary_accuracy: 0.59 - ETA: 13s - loss: 0.6596 - binary_accuracy: 0.65 - ETA: 8s - loss: 0.6723 - binary_accuracy: 0.6484 - ETA: 5s - loss: 0.6465 - binary_accuracy: 0.675 - ETA: 4s - loss: 0.6401 - binary_accuracy: 0.677 - ETA: 2s - loss: 0.6593 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6465 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6328 - binary_accuracy: 0.678 - 6s 17ms/sample - loss: 0.6387 - binary_accuracy: 0.6726\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7214 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6392 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5920 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6263 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6186 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6172 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5748 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6381 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6128 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6031 - binary_accuracy: 0.691 - 0s 1ms/sample - loss: 0.6082 - binary_accuracy: 0.6814\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5871 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5712 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5835 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.684 - 1s 1ms/sample - loss: 0.6174 - binary_accuracy: 0.6755\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5474 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6126 - binary_accuracy: 0.6932\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5764 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5586 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5818 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6169 - binary_accuracy: 0.677 - 1s 2ms/sample - loss: 0.6140 - binary_accuracy: 0.6873\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5638 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5765 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6125 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5980 - binary_accuracy: 0.697 - 1s 2ms/sample - loss: 0.6023 - binary_accuracy: 0.6991\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5868 - binary_accuracy: 0.718 - 1s 1ms/sample - loss: 0.5976 - binary_accuracy: 0.7080\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5443 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6136 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.680 - 0s 1ms/sample - loss: 0.5906 - binary_accuracy: 0.7080\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6275 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6370 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6065 - binary_accuracy: 0.708 - 1s 2ms/sample - loss: 0.5916 - binary_accuracy: 0.7227\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5454 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5747 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5619 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5641 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5487 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.5693 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6004 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5664 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5613 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5882 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5833 - binary_accuracy: 0.715 - 1s 2ms/sample - loss: 0.5928 - binary_accuracy: 0.7021\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 51s - loss: 0.6845 - binary_accuracy: 0.62 - ETA: 13s - loss: 0.6406 - binary_accuracy: 0.68 - ETA: 9s - loss: 0.6515 - binary_accuracy: 0.6719 - ETA: 4s - loss: 0.6193 - binary_accuracy: 0.697 - ETA: 2s - loss: 0.6274 - binary_accuracy: 0.692 - ETA: 1s - loss: 0.6505 - binary_accuracy: 0.670 - 6s 17ms/sample - loss: 0.6408 - binary_accuracy: 0.6755\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5398 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6144 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.684 - 0s 1ms/sample - loss: 0.6170 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7135 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6212 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6311 - binary_accuracy: 0.673 - 0s 1ms/sample - loss: 0.6190 - binary_accuracy: 0.6873\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5284 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5841 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6155 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6181 - binary_accuracy: 0.6814\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5831 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6039 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.5917 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.680 - 1s 2ms/sample - loss: 0.5969 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6826 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6057 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5798 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6351 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6095 - binary_accuracy: 0.6873\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5751 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5882 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6000 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.700 - 1s 2ms/sample - loss: 0.5955 - binary_accuracy: 0.7021\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6399 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5967 - binary_accuracy: 0.7080\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6847 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6446 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6315 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6053 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6064 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6030 - binary_accuracy: 0.6814\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5420 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5821 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5857 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5876 - binary_accuracy: 0.712 - 1s 1ms/sample - loss: 0.5865 - binary_accuracy: 0.7139\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5206 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5315 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5609 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5509 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5563 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5600 - binary_accuracy: 0.718 - 0s 1ms/sample - loss: 0.5729 - binary_accuracy: 0.7080\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 47s - loss: 0.6950 - binary_accuracy: 0.56 - ETA: 12s - loss: 0.6478 - binary_accuracy: 0.70 - ETA: 5s - loss: 0.6290 - binary_accuracy: 0.7188 - ETA: 2s - loss: 0.6478 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6618 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6492 - binary_accuracy: 0.681 - 5s 16ms/sample - loss: 0.6440 - binary_accuracy: 0.6844\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5516 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5686 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6156 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.704 - 0s 1ms/sample - loss: 0.6158 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5665 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.700 - 0s 1ms/sample - loss: 0.6164 - binary_accuracy: 0.6932\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5695 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5493 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5573 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5931 - binary_accuracy: 0.708 - 0s 1ms/sample - loss: 0.6182 - binary_accuracy: 0.6903\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5807 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6130 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6156 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6107 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.696 - 1s 1ms/sample - loss: 0.6125 - binary_accuracy: 0.6903\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5424 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5368 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5699 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5839 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5884 - binary_accuracy: 0.709 - 1s 2ms/sample - loss: 0.6027 - binary_accuracy: 0.6991\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6837 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6076 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6049 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5862 - binary_accuracy: 0.725 - 1s 2ms/sample - loss: 0.6023 - binary_accuracy: 0.7050\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5756 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5391 - binary_accuracy: 0.791 - ETA: 0s - loss: 0.5586 - binary_accuracy: 0.756 - ETA: 0s - loss: 0.5828 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.715 - 0s 1ms/sample - loss: 0.6070 - binary_accuracy: 0.6962\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6906 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6155 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6125 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.653 - 1s 2ms/sample - loss: 0.6156 - binary_accuracy: 0.6608\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5176 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5897 - binary_accuracy: 0.711 - 0s 1ms/sample - loss: 0.5966 - binary_accuracy: 0.7050\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5787 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5768 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5864 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5801 - binary_accuracy: 0.736 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5907 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5890 - binary_accuracy: 0.715 - 1s 2ms/sample - loss: 0.5898 - binary_accuracy: 0.7168\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5062 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5389 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5606 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5949 - binary_accuracy: 0.706 - 0s 1ms/sample - loss: 0.5924 - binary_accuracy: 0.7080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: efc70869a7d78c6ee79c9e9e295f8923</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7177974581718445</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 43s - loss: 0.6779 - binary_accuracy: 0.53 - ETA: 11s - loss: 0.6881 - binary_accuracy: 0.50 - ETA: 5s - loss: 0.6865 - binary_accuracy: 0.5437 - ETA: 2s - loss: 0.6848 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6834 - binary_accuracy: 0.566 - 5s 15ms/sample - loss: 0.6826 - binary_accuracy: 0.5723\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6834 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6547 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6575 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6577 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6595 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6578 - binary_accuracy: 0.666 - 1s 2ms/sample - loss: 0.6536 - binary_accuracy: 0.6785\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.6369 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6379 - binary_accuracy: 0.704 - 1s 2ms/sample - loss: 0.6467 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5639 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.691 - 0s 1ms/sample - loss: 0.6272 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5851 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6296 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5583 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6119 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6160 - binary_accuracy: 0.687 - 1s 1ms/sample - loss: 0.6178 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6471 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6474 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.691 - 0s 1ms/sample - loss: 0.6135 - binary_accuracy: 0.6873\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4749 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5260 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5526 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5739 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5834 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.691 - 1s 2ms/sample - loss: 0.6109 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6538 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6218 - binary_accuracy: 0.681 - 1s 1ms/sample - loss: 0.6206 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6440 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6251 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6257 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5459 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6697 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6372 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6451 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6369 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6150 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6074 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6558 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6693 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.6362 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6220 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6220 - binary_accuracy: 0.684 - 0s 1ms/sample - loss: 0.6195 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 46s - loss: 0.6762 - binary_accuracy: 0.62 - ETA: 12s - loss: 0.6804 - binary_accuracy: 0.56 - ETA: 5s - loss: 0.6718 - binary_accuracy: 0.6250 - ETA: 2s - loss: 0.6643 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6613 - binary_accuracy: 0.649 - 5s 16ms/sample - loss: 0.6632 - binary_accuracy: 0.6342\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6651 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6581 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6587 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6501 - binary_accuracy: 0.668 - 0s 1ms/sample - loss: 0.6463 - binary_accuracy: 0.6755\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6300 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6229 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6348 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6486 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.677 - 1s 2ms/sample - loss: 0.6337 - binary_accuracy: 0.6873\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6662 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6551 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6482 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6297 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6578 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6301 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6278 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6529 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6350 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6319 - binary_accuracy: 0.670 - 1s 2ms/sample - loss: 0.6212 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7398 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.6254 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.5938 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6105 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5341 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6375 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.666 - 0s 1ms/sample - loss: 0.6245 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5245 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5724 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5337 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5640 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5627 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5885 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6083 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5834 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6409 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6074 - binary_accuracy: 0.690 - 0s 1ms/sample - loss: 0.6140 - binary_accuracy: 0.6814\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6281 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6475 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6204 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6134 - binary_accuracy: 0.687 - 0s 1ms/sample - loss: 0.6140 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6589 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5811 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6070 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.694 - 0s 1ms/sample - loss: 0.6094 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 54s - loss: 0.6904 - binary_accuracy: 0.56 - ETA: 24s - loss: 0.6936 - binary_accuracy: 0.56 - ETA: 14s - loss: 0.6929 - binary_accuracy: 0.55 - ETA: 9s - loss: 0.6876 - binary_accuracy: 0.5625 - ETA: 6s - loss: 0.6882 - binary_accuracy: 0.543 - ETA: 4s - loss: 0.6859 - binary_accuracy: 0.552 - ETA: 3s - loss: 0.6839 - binary_accuracy: 0.562 - ETA: 1s - loss: 0.6840 - binary_accuracy: 0.562 - ETA: 1s - loss: 0.6860 - binary_accuracy: 0.555 - ETA: 0s - loss: 0.6845 - binary_accuracy: 0.568 - 6s 19ms/sample - loss: 0.6807 - binary_accuracy: 0.5841\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6783 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.6944 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6896 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6810 - binary_accuracy: 0.601 - ETA: 0s - loss: 0.6729 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6687 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6610 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6557 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6557 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6575 - binary_accuracy: 0.6755\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5851 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6323 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6431 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6385 - binary_accuracy: 0.677 - 1s 2ms/sample - loss: 0.6324 - binary_accuracy: 0.6903\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6804 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.694 - 1s 2ms/sample - loss: 0.6349 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6055 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6314 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6225 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6265 - binary_accuracy: 0.680 - 1s 2ms/sample - loss: 0.6234 - binary_accuracy: 0.6814\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6531 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6283 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6406 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6294 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5886 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6200 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6370 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6245 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6247 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6770 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6271 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6194 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6139 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6622 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.680 - 1s 2ms/sample - loss: 0.6172 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6978 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6261 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6175 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6195 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6193 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7382 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.6799 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6459 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6312 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6219 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6127 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7036 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6245 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6148 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6048 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5819 - binary_accuracy: 0.730 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6178 - binary_accuracy: 0.6814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 8505f2fc393ed60d8e7a7a6694360dfd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6882989406585693</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 54s - loss: 0.6888 - binary_accuracy: 0.56 - ETA: 24s - loss: 0.6853 - binary_accuracy: 0.60 - ETA: 14s - loss: 0.6371 - binary_accuracy: 0.66 - ETA: 9s - loss: 0.6606 - binary_accuracy: 0.6641 - ETA: 4s - loss: 0.6529 - binary_accuracy: 0.666 - ETA: 1s - loss: 0.6554 - binary_accuracy: 0.652 - ETA: 1s - loss: 0.6494 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6409 - binary_accuracy: 0.675 - 6s 18ms/sample - loss: 0.6281 - binary_accuracy: 0.6873\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7649 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6948 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6842 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6735 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6668 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6548 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6523 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6512 - binary_accuracy: 0.6785\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6274 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6135 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6094 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6203 - binary_accuracy: 0.691 - 1s 2ms/sample - loss: 0.6124 - binary_accuracy: 0.6932\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5575 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6075 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6306 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6300 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6225 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6178 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6129 - binary_accuracy: 0.6932\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4945 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5403 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5901 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5937 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.6102 - binary_accuracy: 0.7109\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5834 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6216 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6168 - binary_accuracy: 0.701 - 0s 1ms/sample - loss: 0.6173 - binary_accuracy: 0.6932\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.5981 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.687 - 0s 1ms/sample - loss: 0.6155 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6621 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6432 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6326 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6226 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6771 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6763 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6808 - binary_accuracy: 0.612 - ETA: 0s - loss: 0.6816 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6489 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6380 - binary_accuracy: 0.681 - 1s 1ms/sample - loss: 0.6361 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6266 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6288 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6222 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.691 - 1s 2ms/sample - loss: 0.6284 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5877 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6290 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6259 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6417 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5823 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5931 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6101 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6313 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.6827 - binary_accuracy: 0.56 - ETA: 11s - loss: 0.6901 - binary_accuracy: 0.55 - ETA: 5s - loss: 0.6337 - binary_accuracy: 0.6313 - ETA: 3s - loss: 0.6380 - binary_accuracy: 0.635 - ETA: 2s - loss: 0.6392 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6517 - binary_accuracy: 0.628 - 5s 15ms/sample - loss: 0.6426 - binary_accuracy: 0.6431\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.8673 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.7091 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6562 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6735 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6632 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6599 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6548 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6460 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6378 - binary_accuracy: 0.6814\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6667 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6516 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6928 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6797 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6467 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6500 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6392 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6371 - binary_accuracy: 0.6814\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5700 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5625 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6074 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6302 - binary_accuracy: 0.673 - 0s 1ms/sample - loss: 0.6229 - binary_accuracy: 0.6903\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6251 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.680 - 0s 1ms/sample - loss: 0.6116 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5661 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.666 - 1s 1ms/sample - loss: 0.6092 - binary_accuracy: 0.6903\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6979 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6936 - binary_accuracy: 0.572 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.6563 - binary_accuracy: 0.618 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.668 - 1s 2ms/sample - loss: 0.6209 - binary_accuracy: 0.6814\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5725 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.5876 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5729 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5997 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.5973 - binary_accuracy: 0.6962\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5049 - binary_accuracy: 0.937 - ETA: 0s - loss: 0.5717 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5691 - binary_accuracy: 0.757 - ETA: 0s - loss: 0.5562 - binary_accuracy: 0.755 - ETA: 0s - loss: 0.6066 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6245 - binary_accuracy: 0.684 - 1s 1ms/sample - loss: 0.6208 - binary_accuracy: 0.6903\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5962 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6226 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6125 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6287 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6147 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6104 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5159 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5785 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6049 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6429 - binary_accuracy: 0.620 - ETA: 0s - loss: 0.6332 - binary_accuracy: 0.628 - ETA: 0s - loss: 0.6314 - binary_accuracy: 0.628 - 1s 2ms/sample - loss: 0.6197 - binary_accuracy: 0.6460\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5689 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5736 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6093 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6111 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 45s - loss: 0.7388 - binary_accuracy: 0.31 - ETA: 12s - loss: 0.7264 - binary_accuracy: 0.41 - ETA: 8s - loss: 0.7260 - binary_accuracy: 0.4375 - ETA: 3s - loss: 0.6850 - binary_accuracy: 0.531 - ETA: 1s - loss: 0.6885 - binary_accuracy: 0.558 - ETA: 0s - loss: 0.6644 - binary_accuracy: 0.596 - 5s 15ms/sample - loss: 0.6543 - binary_accuracy: 0.6106\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4869 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5828 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5796 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.6241 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6159 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6117 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6178 - binary_accuracy: 0.6932\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6248 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6124 - binary_accuracy: 0.6814\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4966 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6827 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6611 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6392 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6401 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6300 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7068 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6568 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6332 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.675 - 0s 1ms/sample - loss: 0.6228 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5782 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5964 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5943 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5958 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6067 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6361 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6221 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6136 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6022 - binary_accuracy: 0.6962\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6973 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6695 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6514 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6456 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6325 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6288 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6716 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6467 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6348 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6022 - binary_accuracy: 0.6873\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6484 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6457 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6125 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6233 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6208 - binary_accuracy: 0.665 - 1s 2ms/sample - loss: 0.6177 - binary_accuracy: 0.6755\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6059 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6166 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.6547 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5810 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6099 - binary_accuracy: 0.680 - 1s 1ms/sample - loss: 0.6100 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1762e046fba82dd92108814ae373f48b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7010815739631653</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 59s - loss: 0.6828 - binary_accuracy: 0.59 - ETA: 26s - loss: 0.7250 - binary_accuracy: 0.67 - ETA: 15s - loss: 0.7853 - binary_accuracy: 0.57 - ETA: 7s - loss: 0.7490 - binary_accuracy: 0.5938 - ETA: 4s - loss: 0.7282 - binary_accuracy: 0.609 - ETA: 3s - loss: 0.7163 - binary_accuracy: 0.616 - ETA: 2s - loss: 0.6995 - binary_accuracy: 0.644 - ETA: 1s - loss: 0.6943 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6867 - binary_accuracy: 0.650 - 7s 20ms/sample - loss: 0.6801 - binary_accuracy: 0.6549\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7114 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6701 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6809 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6504 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6481 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6374 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6366 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6383 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6328 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6858 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6495 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6458 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6203 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6169 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6165 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6218 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6066 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6248 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6274 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6292 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6048 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6185 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6201 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7136 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6167 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6159 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6233 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6228 - binary_accuracy: 0.6873\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5597 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5851 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6074 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6155 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6170 - binary_accuracy: 0.6991\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5977 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6170 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.6076 - binary_accuracy: 0.7080\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6064 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6480 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6492 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6555 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6428 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6369 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6410 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6350 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6912 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6362 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6156 - binary_accuracy: 0.691 - 1s 2ms/sample - loss: 0.6233 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6918 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6447 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5854 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6160 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6256 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6288 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6271 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6315 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6245 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6224 - binary_accuracy: 0.6814\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.6816 - binary_accuracy: 0.46 - ETA: 11s - loss: 0.8420 - binary_accuracy: 0.46 - ETA: 7s - loss: 0.7991 - binary_accuracy: 0.4922 - ETA: 5s - loss: 0.7458 - binary_accuracy: 0.562 - ETA: 3s - loss: 0.7190 - binary_accuracy: 0.588 - ETA: 2s - loss: 0.7083 - binary_accuracy: 0.602 - ETA: 1s - loss: 0.6949 - binary_accuracy: 0.621 - ETA: 0s - loss: 0.6884 - binary_accuracy: 0.628 - ETA: 0s - loss: 0.6745 - binary_accuracy: 0.640 - 5s 14ms/sample - loss: 0.6734 - binary_accuracy: 0.6372\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6799 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.715 - 1s 2ms/sample - loss: 0.6033 - binary_accuracy: 0.7227\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6630 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6233 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6690 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6555 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6538 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6405 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6387 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6343 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5630 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5799 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.6007 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6312 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5925 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6258 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6338 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6303 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6293 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6367 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6306 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6262 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6225 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6128 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6181 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5234 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5736 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5446 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6136 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6165 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6196 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6520 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6169 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6001 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6219 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6240 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5900 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5628 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6062 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6258 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6362 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6728 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6601 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6560 - binary_accuracy: 0.618 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6194 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6174 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6966 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6512 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5859 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.6076 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6185 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5638 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6180 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.5861 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6155 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6130 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 49s - loss: 0.6766 - binary_accuracy: 0.62 - ETA: 22s - loss: 0.8103 - binary_accuracy: 0.62 - ETA: 13s - loss: 0.9076 - binary_accuracy: 0.52 - ETA: 8s - loss: 0.8469 - binary_accuracy: 0.5625 - ETA: 6s - loss: 0.7927 - binary_accuracy: 0.600 - ETA: 4s - loss: 0.7698 - binary_accuracy: 0.614 - ETA: 2s - loss: 0.7622 - binary_accuracy: 0.616 - ETA: 1s - loss: 0.7530 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.7385 - binary_accuracy: 0.625 - 6s 17ms/sample - loss: 0.7271 - binary_accuracy: 0.6254\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6425 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6377 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6317 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6361 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6510 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6333 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6329 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7092 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6447 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6380 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6490 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6352 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6167 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6317 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6777 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6352 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6343 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6420 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6290 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6292 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5872 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6224 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6271 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.670 - 1s 2ms/sample - loss: 0.6198 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5816 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6127 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6402 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6354 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6010 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6240 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4876 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5745 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6095 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6412 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6201 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6328 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6318 - binary_accuracy: 0.6785\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.680 - 1s 2ms/sample - loss: 0.6226 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6912 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5897 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6007 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6171 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6528 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6515 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6451 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6464 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6400 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6335 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c4a79a8be6e11431f417f0bcd54008b7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7050147652626038</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 51s - loss: 0.6449 - binary_accuracy: 0.68 - ETA: 23s - loss: 0.6655 - binary_accuracy: 0.67 - ETA: 14s - loss: 0.6794 - binary_accuracy: 0.65 - ETA: 9s - loss: 0.6782 - binary_accuracy: 0.6484 - ETA: 6s - loss: 0.6584 - binary_accuracy: 0.668 - ETA: 4s - loss: 0.6544 - binary_accuracy: 0.671 - ETA: 3s - loss: 0.6484 - binary_accuracy: 0.674 - ETA: 1s - loss: 0.6425 - binary_accuracy: 0.679 - ETA: 1s - loss: 0.6332 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.684 - 6s 18ms/sample - loss: 0.6389 - binary_accuracy: 0.6814\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6241 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6287 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6263 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.6096 - binary_accuracy: 0.6932\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7570 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.7037 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6754 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6531 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6464 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6351 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6245 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.706 - 1s 3ms/sample - loss: 0.6157 - binary_accuracy: 0.7021\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6644 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6488 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6010 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5888 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.6051 - binary_accuracy: 0.7139\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6058 - binary_accuracy: 0.6932\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5151 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5413 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6287 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6248 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.709 - 1s 3ms/sample - loss: 0.6072 - binary_accuracy: 0.7080\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6402 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6244 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5851 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5860 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5839 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6066 - binary_accuracy: 0.6903\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5699 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5854 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5884 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5956 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.5952 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.5926 - binary_accuracy: 0.7080\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4740 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5025 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5068 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5366 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5603 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5631 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5850 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.715 - 1s 2ms/sample - loss: 0.5906 - binary_accuracy: 0.7109\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5503 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5789 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5794 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5810 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5936 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5845 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.5887 - binary_accuracy: 0.7198\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5482 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5049 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5448 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5435 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5696 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5649 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5727 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.5977 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.5927 - binary_accuracy: 0.6962\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6696 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6056 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5858 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5788 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5910 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5796 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5773 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5684 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5690 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5729 - binary_accuracy: 0.712 - 1s 3ms/sample - loss: 0.5812 - binary_accuracy: 0.7080\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 48s - loss: 0.6737 - binary_accuracy: 0.62 - ETA: 22s - loss: 0.6662 - binary_accuracy: 0.62 - ETA: 13s - loss: 0.6456 - binary_accuracy: 0.64 - ETA: 8s - loss: 0.6374 - binary_accuracy: 0.6562 - ETA: 5s - loss: 0.6173 - binary_accuracy: 0.681 - ETA: 4s - loss: 0.6143 - binary_accuracy: 0.697 - ETA: 2s - loss: 0.6402 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6267 - binary_accuracy: 0.691 - ETA: 1s - loss: 0.6269 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6290 - binary_accuracy: 0.690 - 6s 17ms/sample - loss: 0.6294 - binary_accuracy: 0.6873\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6987 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5832 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5910 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6329 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6267 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6287 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5722 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5858 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5848 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.5911 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6185 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6238 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6137 - binary_accuracy: 0.7050\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7052 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6713 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6631 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6281 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6295 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6233 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6208 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6141 - binary_accuracy: 0.671 - 1s 3ms/sample - loss: 0.6159 - binary_accuracy: 0.6696\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5172 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5615 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5860 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5933 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5742 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6056 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5600 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5314 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5605 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5722 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5832 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5890 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5864 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5831 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6025 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4673 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5580 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5522 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5331 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5641 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5873 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5816 - binary_accuracy: 0.709 - 1s 3ms/sample - loss: 0.5787 - binary_accuracy: 0.7139\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6589 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5870 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5863 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5757 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6012 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5913 - binary_accuracy: 0.706 - 1s 3ms/sample - loss: 0.5851 - binary_accuracy: 0.7109\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.5952 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5683 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5625 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5519 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5529 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5478 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5588 - binary_accuracy: 0.730 - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5917 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5988 - binary_accuracy: 0.6991\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6649 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6333 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6352 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6366 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6068 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5917 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6125 - binary_accuracy: 0.6785\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5821 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5740 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5803 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5783 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5781 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.5888 - binary_accuracy: 0.6991\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5072 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6127 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5878 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5792 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5758 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5869 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.709 - 1s 3ms/sample - loss: 0.5932 - binary_accuracy: 0.7080\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.6752 - binary_accuracy: 0.65 - ETA: 19s - loss: 0.6695 - binary_accuracy: 0.65 - ETA: 11s - loss: 0.6486 - binary_accuracy: 0.66 - ETA: 7s - loss: 0.6261 - binary_accuracy: 0.6953 - ETA: 5s - loss: 0.6337 - binary_accuracy: 0.681 - ETA: 3s - loss: 0.6407 - binary_accuracy: 0.671 - ETA: 2s - loss: 0.6419 - binary_accuracy: 0.669 - ETA: 1s - loss: 0.6384 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6413 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.668 - 5s 15ms/sample - loss: 0.6380 - binary_accuracy: 0.6637\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5605 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5477 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5783 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6171 - binary_accuracy: 0.6637\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.5685 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6537 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6418 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6330 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6071 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6126 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7479 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6597 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6385 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6320 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6127 - binary_accuracy: 0.6755\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4934 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6101 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6213 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6100 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.5952 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7433 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.6628 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5806 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.5980 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6474 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5517 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5359 - binary_accuracy: 0.791 - ETA: 0s - loss: 0.5580 - binary_accuracy: 0.757 - ETA: 0s - loss: 0.5709 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5842 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5704 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5753 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5806 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5728 - binary_accuracy: 0.718 - 1s 2ms/sample - loss: 0.5780 - binary_accuracy: 0.7080\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5118 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5585 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5758 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6200 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6226 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6138 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6177 - binary_accuracy: 0.6785\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6659 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5956 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6154 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6005 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6580 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5944 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5962 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6076 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.5875 - binary_accuracy: 0.7021\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5606 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5726 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5581 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5646 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.6054 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5828 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5911 - binary_accuracy: 0.7021\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5621 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5928 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.5986 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5902 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5744 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.6129 - binary_accuracy: 0.6903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 72289c8df8680aff6ca457005c6e8bfc</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7138643264770508</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 50s - loss: 0.6972 - binary_accuracy: 0.46 - ETA: 23s - loss: 1.5872 - binary_accuracy: 0.56 - ETA: 13s - loss: 2.0428 - binary_accuracy: 0.50 - ETA: 9s - loss: 1.7026 - binary_accuracy: 0.5312 - ETA: 6s - loss: 1.4884 - binary_accuracy: 0.562 - ETA: 4s - loss: 1.3701 - binary_accuracy: 0.546 - ETA: 3s - loss: 1.2742 - binary_accuracy: 0.540 - ETA: 1s - loss: 1.1934 - binary_accuracy: 0.562 - ETA: 1s - loss: 1.1332 - binary_accuracy: 0.572 - ETA: 0s - loss: 1.0691 - binary_accuracy: 0.600 - 6s 19ms/sample - loss: 1.0369 - binary_accuracy: 0.6106\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.9299 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.7702 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.7244 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6934 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6872 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6705 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6681 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6678 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6566 - binary_accuracy: 0.671 - 1s 3ms/sample - loss: 0.6490 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6372 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6211 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5674 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5885 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6506 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6315 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6383 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6848 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6501 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6263 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6435 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6405 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6339 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6317 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6336 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6064 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6203 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6148 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6134 - binary_accuracy: 0.693 - 1s 4ms/sample - loss: 0.6220 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6146 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5502 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6295 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6194 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6175 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6219 - binary_accuracy: 0.690 - 1s 4ms/sample - loss: 0.6261 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6066 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6229 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6286 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6339 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6336 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5485 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5845 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5662 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6262 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.690 - 1s 4ms/sample - loss: 0.6281 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6438 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6355 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6316 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6444 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6614 - binary_accuracy: 0.625 - ETA: 1s - loss: 0.6535 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6615 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6521 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6486 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.678 - 1s 4ms/sample - loss: 0.6279 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.4993 - binary_accuracy: 0.843 - ETA: 1s - loss: 0.5276 - binary_accuracy: 0.812 - ETA: 1s - loss: 0.5720 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6119 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5990 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6328 - binary_accuracy: 0.693 - 1s 4ms/sample - loss: 0.6409 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6570 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6578 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6570 - binary_accuracy: 0.633 - ETA: 0s - loss: 0.6491 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6457 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6414 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 45s - loss: 0.6757 - binary_accuracy: 0.68 - ETA: 20s - loss: 2.4070 - binary_accuracy: 0.59 - ETA: 12s - loss: 2.5181 - binary_accuracy: 0.50 - ETA: 8s - loss: 2.0583 - binary_accuracy: 0.5391 - ETA: 5s - loss: 1.7706 - binary_accuracy: 0.575 - ETA: 3s - loss: 1.5735 - binary_accuracy: 0.599 - ETA: 2s - loss: 1.4377 - binary_accuracy: 0.611 - ETA: 1s - loss: 1.3443 - binary_accuracy: 0.613 - ETA: 0s - loss: 1.2622 - binary_accuracy: 0.625 - ETA: 0s - loss: 1.1931 - binary_accuracy: 0.637 - 6s 17ms/sample - loss: 1.1599 - binary_accuracy: 0.6431\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6081 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6508 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6161 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6226 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6287 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6669 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6720 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6569 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6613 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6612 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6595 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6491 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6502 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6414 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6451 - binary_accuracy: 0.678 - 1s 4ms/sample - loss: 0.6387 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6382 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6485 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6921 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6436 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6236 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6491 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6423 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6355 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.6379 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6078 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6691 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6567 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6384 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6354 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6144 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6346 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6329 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6415 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6332 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6200 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6212 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6222 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6307 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5682 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6170 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6467 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6224 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6136 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6273 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6268 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6274 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6302 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6205 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6262 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6270 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6160 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6283 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6243 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6259 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6785 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6881 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6639 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6426 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6482 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6366 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6352 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6386 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6366 - binary_accuracy: 0.675 - 1s 3ms/sample - loss: 0.6298 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6826 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6819 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.583 - ETA: 0s - loss: 0.6830 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6431 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6242 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7972 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.7059 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6875 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6862 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6732 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6552 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6415 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6336 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6308 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 50s - loss: 0.6576 - binary_accuracy: 0.68 - ETA: 22s - loss: 2.1680 - binary_accuracy: 0.64 - ETA: 13s - loss: 2.2441 - binary_accuracy: 0.56 - ETA: 9s - loss: 1.8434 - binary_accuracy: 0.5938 - ETA: 6s - loss: 1.5809 - binary_accuracy: 0.631 - ETA: 4s - loss: 1.4372 - binary_accuracy: 0.630 - ETA: 2s - loss: 1.3222 - binary_accuracy: 0.638 - ETA: 1s - loss: 1.2367 - binary_accuracy: 0.644 - ETA: 1s - loss: 1.1702 - binary_accuracy: 0.645 - ETA: 0s - loss: 1.1083 - binary_accuracy: 0.659 - 6s 18ms/sample - loss: 1.0839 - binary_accuracy: 0.6578\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6698 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6211 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6203 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6258 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6270 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 1s - loss: 0.5940 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6104 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6301 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6260 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6185 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6251 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6164 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6129 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6352 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.671 - 1s 4ms/sample - loss: 0.6283 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5794 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5859 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6119 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6302 - binary_accuracy: 0.678 - 1s 4ms/sample - loss: 0.6270 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6044 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.6633 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6628 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6482 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6323 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6242 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5953 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.6424 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6181 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6295 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6241 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6226 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6074 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6051 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6280 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6258 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6621 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6407 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6406 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6400 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6335 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6221 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.7456 - binary_accuracy: 0.531 - ETA: 0s - loss: 0.6617 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6414 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6467 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6280 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6224 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6195 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6283 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.675 - 1s 3ms/sample - loss: 0.6253 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7333 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.7189 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6915 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6794 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.6628 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6474 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6541 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6537 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6357 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5315 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5786 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6374 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6485 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6445 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6488 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6355 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6311 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6320 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.6340 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c27bf29b0da3856a9744729bcb3825cc</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6843658089637756</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 57s - loss: 0.7171 - binary_accuracy: 0.40 - ETA: 26s - loss: 0.6446 - binary_accuracy: 0.57 - ETA: 15s - loss: 0.6572 - binary_accuracy: 0.61 - ETA: 10s - loss: 0.6525 - binary_accuracy: 0.64 - ETA: 7s - loss: 0.6535 - binary_accuracy: 0.6375 - ETA: 4s - loss: 0.6439 - binary_accuracy: 0.651 - ETA: 3s - loss: 0.6438 - binary_accuracy: 0.651 - ETA: 2s - loss: 0.6457 - binary_accuracy: 0.648 - ETA: 1s - loss: 0.6411 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6455 - binary_accuracy: 0.650 - 7s 21ms/sample - loss: 0.6499 - binary_accuracy: 0.6460\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5830 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5775 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6065 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5962 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6135 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.6148 - binary_accuracy: 0.6962\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.3925 - binary_accuracy: 0.906 - ETA: 0s - loss: 0.4613 - binary_accuracy: 0.828 - ETA: 0s - loss: 0.5796 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6288 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6445 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6464 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6505 - binary_accuracy: 0.644 - ETA: 0s - loss: 0.6453 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6444 - binary_accuracy: 0.656 - 1s 3ms/sample - loss: 0.6436 - binary_accuracy: 0.6549\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5884 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6127 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5970 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.709 - 1s 3ms/sample - loss: 0.6118 - binary_accuracy: 0.6932\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6511 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5691 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5702 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5874 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5843 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5809 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.6014 - binary_accuracy: 0.6991\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7141 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6216 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5693 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5687 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.696 - 1s 4ms/sample - loss: 0.6338 - binary_accuracy: 0.6785\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5680 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5598 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6338 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6175 - binary_accuracy: 0.6903\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7230 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6440 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6471 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6204 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6133 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.5933 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6000 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5882 - binary_accuracy: 0.7021\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.3957 - binary_accuracy: 0.875 - ETA: 0s - loss: 0.5364 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5296 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5280 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5267 - binary_accuracy: 0.756 - ETA: 0s - loss: 0.5561 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5717 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.5737 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5779 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5888 - binary_accuracy: 0.712 - 1s 4ms/sample - loss: 0.5913 - binary_accuracy: 0.7139\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6644 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6161 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5962 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.5973 - binary_accuracy: 0.6962\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5220 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5387 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5608 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5763 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5812 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.668 - 1s 3ms/sample - loss: 0.6097 - binary_accuracy: 0.6785\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6350 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.5745 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5610 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5727 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5757 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5952 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5809 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5880 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5970 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6030 - binary_accuracy: 0.6814\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 52s - loss: 0.6889 - binary_accuracy: 0.53 - ETA: 24s - loss: 0.6767 - binary_accuracy: 0.57 - ETA: 14s - loss: 0.6714 - binary_accuracy: 0.60 - ETA: 9s - loss: 0.6591 - binary_accuracy: 0.6250 - ETA: 6s - loss: 0.6400 - binary_accuracy: 0.650 - ETA: 4s - loss: 0.6179 - binary_accuracy: 0.671 - ETA: 3s - loss: 0.6194 - binary_accuracy: 0.669 - ETA: 2s - loss: 0.6088 - binary_accuracy: 0.683 - ETA: 1s - loss: 0.6156 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.671 - 7s 19ms/sample - loss: 0.6222 - binary_accuracy: 0.6667\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6790 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6926 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6826 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6539 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.6537 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6651 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6638 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6607 - binary_accuracy: 0.621 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6561 - binary_accuracy: 0.637 - 1s 3ms/sample - loss: 0.6452 - binary_accuracy: 0.6519\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6657 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6463 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6300 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5990 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.6020 - binary_accuracy: 0.6903\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5587 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6619 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6519 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6313 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6156 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6221 - binary_accuracy: 0.6696\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6399 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.7091 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6684 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6717 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6665 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6645 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.642 - ETA: 0s - loss: 0.6511 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6442 - binary_accuracy: 0.659 - ETA: 0s - loss: 0.6406 - binary_accuracy: 0.659 - 1s 3ms/sample - loss: 0.6351 - binary_accuracy: 0.6667\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5682 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6319 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6263 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6528 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6401 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6431 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6457 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6202 - binary_accuracy: 0.6903\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6364 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6520 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6400 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6168 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6004 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5967 - binary_accuracy: 0.7050\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6546 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.7065 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5952 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6056 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.6001 - binary_accuracy: 0.6903\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5889 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5459 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5238 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5395 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5473 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5487 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5765 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5944 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5998 - binary_accuracy: 0.6991\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4724 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5714 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5858 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5801 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5882 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.5882 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.5916 - binary_accuracy: 0.7139\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5368 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5277 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5547 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5704 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5894 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5880 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5958 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5767 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5718 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5869 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5806 - binary_accuracy: 0.7050\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.4780 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5334 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5743 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6380 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6417 - binary_accuracy: 0.630 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6336 - binary_accuracy: 0.644 - ETA: 0s - loss: 0.6280 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6104 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6014 - binary_accuracy: 0.6932\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 51s - loss: 0.6798 - binary_accuracy: 0.56 - ETA: 23s - loss: 0.6194 - binary_accuracy: 0.65 - ETA: 13s - loss: 0.6104 - binary_accuracy: 0.68 - ETA: 9s - loss: 0.6609 - binary_accuracy: 0.6641 - ETA: 6s - loss: 0.6448 - binary_accuracy: 0.675 - ETA: 4s - loss: 0.6317 - binary_accuracy: 0.687 - ETA: 3s - loss: 0.6347 - binary_accuracy: 0.674 - ETA: 1s - loss: 0.6394 - binary_accuracy: 0.664 - ETA: 1s - loss: 0.6405 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6374 - binary_accuracy: 0.659 - 6s 18ms/sample - loss: 0.6387 - binary_accuracy: 0.6549\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5237 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5764 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6004 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6001 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6106 - binary_accuracy: 0.6785\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.6540 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6504 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6477 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6391 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6431 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6365 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6288 - binary_accuracy: 0.642 - ETA: 0s - loss: 0.6129 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5952 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6084 - binary_accuracy: 0.6755\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.3581 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6058 - binary_accuracy: 0.6932\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6288 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5648 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5716 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5733 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5743 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5788 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5842 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5906 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5947 - binary_accuracy: 0.7080\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4653 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5484 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5573 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5834 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6010 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6086 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6014 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5618 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5683 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5896 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5643 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5742 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5700 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.5731 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6068 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.5927 - binary_accuracy: 0.6962\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5434 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5298 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5330 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5574 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5693 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5745 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5874 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5767 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5980 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6012 - binary_accuracy: 0.6873\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5514 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5277 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5418 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5755 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5653 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5658 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5763 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5726 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5792 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.5775 - binary_accuracy: 0.6962\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5627 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5931 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.5913 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5798 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5814 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5816 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.706 - 1s 3ms/sample - loss: 0.5842 - binary_accuracy: 0.7021\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5763 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5957 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5740 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5642 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5936 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5725 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.5776 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5981 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5952 - binary_accuracy: 0.7050\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5561 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5844 - binary_accuracy: 0.734 - 1s 3ms/sample - loss: 0.5865 - binary_accuracy: 0.7286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c8c1ef4527c5833d32e68f7f9956ddd7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7187807559967041</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 49s - loss: 0.6906 - binary_accuracy: 0.50 - ETA: 22s - loss: 0.6807 - binary_accuracy: 0.57 - ETA: 13s - loss: 0.6775 - binary_accuracy: 0.59 - ETA: 8s - loss: 0.6781 - binary_accuracy: 0.5938 - ETA: 6s - loss: 0.6723 - binary_accuracy: 0.618 - ETA: 4s - loss: 0.6601 - binary_accuracy: 0.651 - ETA: 2s - loss: 0.6483 - binary_accuracy: 0.669 - ETA: 1s - loss: 0.6388 - binary_accuracy: 0.683 - ETA: 1s - loss: 0.6497 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6509 - binary_accuracy: 0.656 - 6s 18ms/sample - loss: 0.6501 - binary_accuracy: 0.6578\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5072 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5292 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5669 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5859 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5925 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6311 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6227 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5591 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5734 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5608 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5979 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5880 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6022 - binary_accuracy: 0.6814\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6546 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5633 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5668 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5736 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5926 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.696 - 1s 4ms/sample - loss: 0.6070 - binary_accuracy: 0.6903\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6748 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.7044 - binary_accuracy: 0.546 - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6510 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6376 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6302 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6101 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6068 - binary_accuracy: 0.6903\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6051 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6054 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5553 - binary_accuracy: 0.770 - ETA: 0s - loss: 0.5906 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5858 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5950 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6099 - binary_accuracy: 0.687 - 1s 4ms/sample - loss: 0.6027 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5711 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5822 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5777 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5811 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5798 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5765 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.706 - 1s 4ms/sample - loss: 0.5865 - binary_accuracy: 0.7109\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5846 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.5920 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5828 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.5754 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.5852 - binary_accuracy: 0.6814\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5926 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5957 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5692 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5784 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5773 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5928 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.5844 - binary_accuracy: 0.6962\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5652 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5486 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5629 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5689 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5762 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5694 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5552 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5612 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5674 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5841 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5961 - binary_accuracy: 0.6932\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6556 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6149 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5715 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5691 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5691 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5813 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5717 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5894 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.709 - 1s 3ms/sample - loss: 0.5837 - binary_accuracy: 0.7139\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5815 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6576 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6362 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6148 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6129 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6083 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.7066 - binary_accuracy: 0.40 - ETA: 19s - loss: 0.7018 - binary_accuracy: 0.46 - ETA: 11s - loss: 0.6899 - binary_accuracy: 0.50 - ETA: 7s - loss: 0.6933 - binary_accuracy: 0.4922 - ETA: 5s - loss: 0.6846 - binary_accuracy: 0.531 - ETA: 3s - loss: 0.6720 - binary_accuracy: 0.567 - ETA: 2s - loss: 0.6674 - binary_accuracy: 0.584 - ETA: 1s - loss: 0.6585 - binary_accuracy: 0.605 - ETA: 0s - loss: 0.6460 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6441 - binary_accuracy: 0.631 - 5s 16ms/sample - loss: 0.6429 - binary_accuracy: 0.6342\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4745 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5411 - binary_accuracy: 0.770 - ETA: 0s - loss: 0.5595 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6159 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6265 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6412 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6483 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6476 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6213 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6134 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6069 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5842 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5483 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5858 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6290 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6330 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6200 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6119 - binary_accuracy: 0.6814\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6558 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5915 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5930 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5750 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5831 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6079 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5810 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5621 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5734 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5611 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5651 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5772 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5854 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5911 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5891 - binary_accuracy: 0.706 - 1s 3ms/sample - loss: 0.5979 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5715 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5849 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5836 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5816 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5886 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5979 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5943 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5965 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.5934 - binary_accuracy: 0.6991\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5935 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5898 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6156 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6008 - binary_accuracy: 0.6932\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6799 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.7017 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6477 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6490 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6299 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6051 - binary_accuracy: 0.675 - 1s 3ms/sample - loss: 0.6014 - binary_accuracy: 0.6785\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5990 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5798 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5660 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5930 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6012 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5826 - binary_accuracy: 0.703 - 1s 4ms/sample - loss: 0.5949 - binary_accuracy: 0.6991\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5869 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6245 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5817 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5836 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5784 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5949 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.5937 - binary_accuracy: 0.7021\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6937 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6429 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5824 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.5997 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.5914 - binary_accuracy: 0.6903\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 49s - loss: 0.6934 - binary_accuracy: 0.59 - ETA: 22s - loss: 0.6940 - binary_accuracy: 0.54 - ETA: 13s - loss: 0.6764 - binary_accuracy: 0.61 - ETA: 9s - loss: 0.6586 - binary_accuracy: 0.6641 - ETA: 6s - loss: 0.6561 - binary_accuracy: 0.668 - ETA: 4s - loss: 0.6538 - binary_accuracy: 0.671 - ETA: 2s - loss: 0.6429 - binary_accuracy: 0.683 - ETA: 1s - loss: 0.6351 - binary_accuracy: 0.691 - ETA: 1s - loss: 0.6480 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6456 - binary_accuracy: 0.671 - 6s 18ms/sample - loss: 0.6415 - binary_accuracy: 0.6755\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4647 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5964 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6265 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6328 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6344 - binary_accuracy: 0.675 - 1s 3ms/sample - loss: 0.6233 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.7254 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6528 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6128 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6111 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6064 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5192 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5034 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5421 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5245 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5499 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5823 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5946 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6047 - binary_accuracy: 0.6785\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5204 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5626 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6054 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5986 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6106 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5584 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5811 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5889 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5857 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.6159 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5205 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5981 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6244 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6038 - binary_accuracy: 0.6873\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6225 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6386 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6315 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6208 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6220 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.5999 - binary_accuracy: 0.6962\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5298 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5112 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.4908 - binary_accuracy: 0.770 - ETA: 0s - loss: 0.5196 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5376 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5519 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5680 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5632 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5868 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.5999 - binary_accuracy: 0.6814\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5466 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5518 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5460 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5848 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6054 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.5986 - binary_accuracy: 0.6903\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7255 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6048 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5816 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5808 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.5961 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5417 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5937 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5551 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5371 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5368 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5428 - binary_accuracy: 0.755 - ETA: 0s - loss: 0.5547 - binary_accuracy: 0.741 - ETA: 0s - loss: 0.5690 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5864 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.5955 - binary_accuracy: 0.6873\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 713f054fd6c339f89c7a603559fd6441</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7040314674377441</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 44s - loss: 0.7096 - binary_accuracy: 0.43 - ETA: 20s - loss: 0.6706 - binary_accuracy: 0.59 - ETA: 12s - loss: 1.6182 - binary_accuracy: 0.44 - ETA: 7s - loss: 1.4235 - binary_accuracy: 0.4844 - ETA: 5s - loss: 1.2700 - binary_accuracy: 0.537 - ETA: 3s - loss: 1.1641 - binary_accuracy: 0.562 - ETA: 2s - loss: 1.1008 - binary_accuracy: 0.567 - ETA: 1s - loss: 1.0432 - binary_accuracy: 0.578 - ETA: 0s - loss: 1.0017 - binary_accuracy: 0.583 - ETA: 0s - loss: 0.9598 - binary_accuracy: 0.603 - 5s 16ms/sample - loss: 0.9377 - binary_accuracy: 0.6136\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6602 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6463 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6474 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6520 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6311 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6249 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6262 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6248 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5765 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6156 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6409 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6164 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6227 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6537 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6437 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6287 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6180 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6178 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5880 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6498 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6664 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6520 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6320 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6337 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6180 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6169 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6230 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5245 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6776 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6593 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6427 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6431 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6533 - binary_accuracy: 0.642 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6338 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6294 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5109 - binary_accuracy: 0.828 - ETA: 0s - loss: 0.5699 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6371 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6458 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6329 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6301 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6221 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6266 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5351 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6087 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5905 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6283 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6427 - binary_accuracy: 0.671 - 1s 2ms/sample - loss: 0.6310 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6659 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6708 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6538 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6170 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6386 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6237 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6372 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5714 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5862 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6230 - binary_accuracy: 0.6785\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6403 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6631 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6249 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6166 - binary_accuracy: 0.6932\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 41s - loss: 0.6803 - binary_accuracy: 0.59 - ETA: 18s - loss: 1.7868 - binary_accuracy: 0.56 - ETA: 11s - loss: 1.7633 - binary_accuracy: 0.51 - ETA: 7s - loss: 1.5050 - binary_accuracy: 0.4531 - ETA: 5s - loss: 1.3468 - binary_accuracy: 0.475 - ETA: 3s - loss: 1.2255 - binary_accuracy: 0.510 - ETA: 2s - loss: 1.1435 - binary_accuracy: 0.531 - ETA: 1s - loss: 1.0729 - binary_accuracy: 0.558 - ETA: 0s - loss: 1.0091 - binary_accuracy: 0.590 - ETA: 0s - loss: 0.9656 - binary_accuracy: 0.606 - 5s 15ms/sample - loss: 0.9481 - binary_accuracy: 0.6106\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6339 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.7002 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6781 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6564 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6583 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6525 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6532 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6516 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6444 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6443 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6389 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5639 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5730 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.6445 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6553 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6542 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6607 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6681 - binary_accuracy: 0.638 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6379 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6311 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6396 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6325 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6059 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5930 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6111 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6336 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6254 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6101 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6236 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6134 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6214 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6228 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5806 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6218 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6224 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6364 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6377 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6384 - binary_accuracy: 0.668 - 1s 2ms/sample - loss: 0.6276 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6288 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6000 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6241 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5641 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5691 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6178 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6218 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6245 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6493 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6639 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6496 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6343 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6236 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6221 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6213 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6718 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6301 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6232 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6274 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5990 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6314 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6297 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 47s - loss: 0.7001 - binary_accuracy: 0.37 - ETA: 21s - loss: 1.4653 - binary_accuracy: 0.46 - ETA: 12s - loss: 1.7592 - binary_accuracy: 0.43 - ETA: 8s - loss: 1.4739 - binary_accuracy: 0.5391 - ETA: 5s - loss: 1.3520 - binary_accuracy: 0.556 - ETA: 4s - loss: 1.2377 - binary_accuracy: 0.562 - ETA: 2s - loss: 1.1565 - binary_accuracy: 0.567 - ETA: 1s - loss: 1.0866 - binary_accuracy: 0.593 - ETA: 0s - loss: 1.0527 - binary_accuracy: 0.590 - ETA: 0s - loss: 1.0001 - binary_accuracy: 0.609 - 6s 17ms/sample - loss: 0.9770 - binary_accuracy: 0.6165\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6618 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6702 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6423 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6403 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6473 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6470 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6403 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6310 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.6941 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6747 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6994 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6623 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6361 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6313 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6348 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6317 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6585 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6641 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6435 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6315 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6252 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6266 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6280 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6286 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6384 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6372 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6250 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5884 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5494 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6329 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6395 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6361 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6274 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6266 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6355 - binary_accuracy: 0.675 - 1s 3ms/sample - loss: 0.6287 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6579 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6116 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6330 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6420 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6457 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6477 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6369 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6326 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6255 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6397 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6862 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6515 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6195 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6238 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6291 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6266 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6293 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6453 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6406 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6301 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6333 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6306 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6313 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6204 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6245 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6548 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6218 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5930 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6130 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6197 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6623 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6325 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6486 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6444 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6261 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6312 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6375 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6338 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6292 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6286 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6490 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6376 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6337 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6254 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6257 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1f8cee2aa4c48bd0d65a323c3b663ad1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6873156428337097</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 50s - loss: 0.6965 - binary_accuracy: 0.56 - ETA: 22s - loss: 0.6886 - binary_accuracy: 0.62 - ETA: 13s - loss: 0.6881 - binary_accuracy: 0.58 - ETA: 8s - loss: 0.6915 - binary_accuracy: 0.5469 - ETA: 6s - loss: 0.6916 - binary_accuracy: 0.537 - ETA: 4s - loss: 0.6882 - binary_accuracy: 0.552 - ETA: 2s - loss: 0.6849 - binary_accuracy: 0.571 - ETA: 1s - loss: 0.6847 - binary_accuracy: 0.578 - ETA: 1s - loss: 0.6809 - binary_accuracy: 0.590 - ETA: 0s - loss: 0.6803 - binary_accuracy: 0.593 - 6s 17ms/sample - loss: 0.6773 - binary_accuracy: 0.6018\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7136 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6537 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6573 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6370 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6228 - binary_accuracy: 0.6903\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6286 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6602 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6747 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6460 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6416 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6160 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6205 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6471 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6567 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6469 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6275 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6398 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6310 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5650 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5635 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5718 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.6141 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6213 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6218 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6104 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6194 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5863 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6677 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6319 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6469 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6208 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6119 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5613 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5906 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5938 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5975 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6064 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6129 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5757 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6155 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5865 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5841 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6200 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6201 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6165 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5675 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6282 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6319 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6134 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6055 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6084 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6820 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6133 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6065 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6062 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6164 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6062 - binary_accuracy: 0.6991\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5719 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5540 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5559 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5464 - binary_accuracy: 0.757 - ETA: 0s - loss: 0.5790 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5805 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5861 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5935 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6064 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5577 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5621 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5662 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5729 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5898 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6007 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5890 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.5981 - binary_accuracy: 0.6873\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 56s - loss: 0.6641 - binary_accuracy: 0.65 - ETA: 25s - loss: 0.6808 - binary_accuracy: 0.57 - ETA: 15s - loss: 0.6743 - binary_accuracy: 0.61 - ETA: 10s - loss: 0.6688 - binary_accuracy: 0.63 - ETA: 6s - loss: 0.6658 - binary_accuracy: 0.6500 - ETA: 4s - loss: 0.6604 - binary_accuracy: 0.645 - ETA: 3s - loss: 0.6598 - binary_accuracy: 0.647 - ETA: 2s - loss: 0.6600 - binary_accuracy: 0.644 - ETA: 1s - loss: 0.6513 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6482 - binary_accuracy: 0.671 - 7s 19ms/sample - loss: 0.6496 - binary_accuracy: 0.6696\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6179 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6186 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6295 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6241 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6205 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6178 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6437 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6488 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6332 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6295 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6161 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6510 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5738 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5798 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5931 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6167 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4616 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5201 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5828 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5834 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5980 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6249 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6158 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6601 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5801 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5873 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5985 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6127 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6086 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7043 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6407 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6249 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6071 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6203 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6127 - binary_accuracy: 0.6932\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5544 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5789 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5884 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6062 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6043 - binary_accuracy: 0.6873\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5513 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5822 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5697 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5630 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6062 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6135 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6049 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6070 - binary_accuracy: 0.6755\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5959 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6012 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5923 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5774 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5856 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5935 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6010 - binary_accuracy: 0.6873\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5758 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6590 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6185 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6117 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6125 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.700 - 1s 2ms/sample - loss: 0.6107 - binary_accuracy: 0.6962\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4798 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5859 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6031 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6053 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6111 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6033 - binary_accuracy: 0.6962\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 44s - loss: 0.7060 - binary_accuracy: 0.50 - ETA: 20s - loss: 0.6951 - binary_accuracy: 0.50 - ETA: 12s - loss: 0.6967 - binary_accuracy: 0.48 - ETA: 5s - loss: 0.6934 - binary_accuracy: 0.5063 - ETA: 3s - loss: 0.6903 - binary_accuracy: 0.536 - ETA: 2s - loss: 0.6886 - binary_accuracy: 0.553 - ETA: 1s - loss: 0.6832 - binary_accuracy: 0.574 - ETA: 0s - loss: 0.6825 - binary_accuracy: 0.572 - ETA: 0s - loss: 0.6818 - binary_accuracy: 0.575 - 5s 15ms/sample - loss: 0.6785 - binary_accuracy: 0.5841\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6517 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6528 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6496 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6537 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6476 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6343 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6317 - binary_accuracy: 0.6873\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.6147 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6138 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6031 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6241 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6219 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6178 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7190 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.5802 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6054 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6181 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6251 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6151 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5651 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5582 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6031 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5935 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6187 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6620 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5938 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6129 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6127 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6168 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6133 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6150 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7280 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6881 - binary_accuracy: 0.546 - ETA: 0s - loss: 0.6664 - binary_accuracy: 0.583 - ETA: 0s - loss: 0.6335 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6128 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6156 - binary_accuracy: 0.6814\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5141 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5629 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5891 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6221 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6205 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6042 - binary_accuracy: 0.6873\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5439 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5270 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5806 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5714 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5770 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5917 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6079 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6828 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6377 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6261 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6138 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6066 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6059 - binary_accuracy: 0.6903\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7131 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6456 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6505 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6276 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6119 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.5946 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6000 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6098 - binary_accuracy: 0.6785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2632342a860288013cc530bf4b06b3be</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6951819062232971</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 53s - loss: 0.7050 - binary_accuracy: 0.46 - ETA: 24s - loss: 0.6513 - binary_accuracy: 0.64 - ETA: 14s - loss: 0.6409 - binary_accuracy: 0.65 - ETA: 9s - loss: 0.6375 - binary_accuracy: 0.6641 - ETA: 6s - loss: 0.6592 - binary_accuracy: 0.656 - ETA: 4s - loss: 0.6557 - binary_accuracy: 0.661 - ETA: 3s - loss: 0.6499 - binary_accuracy: 0.665 - ETA: 1s - loss: 0.6521 - binary_accuracy: 0.660 - ETA: 1s - loss: 0.6445 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6528 - binary_accuracy: 0.662 - 6s 19ms/sample - loss: 0.6542 - binary_accuracy: 0.6608\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6577 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6429 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6533 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6531 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6510 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6369 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6163 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6208 - binary_accuracy: 0.6726\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6570 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5928 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5437 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5750 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5812 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6051 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6152 - binary_accuracy: 0.6932\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5615 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5856 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6145 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6188 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6186 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6022 - binary_accuracy: 0.7021\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6604 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.7155 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6743 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6538 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6514 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6347 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6133 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6029 - binary_accuracy: 0.6873\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5990 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5769 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.5943 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6414 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5913 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6063 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6111 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6161 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.6002 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6136 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5843 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5657 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5901 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6056 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5915 - binary_accuracy: 0.709 - 1s 2ms/sample - loss: 0.5931 - binary_accuracy: 0.7080\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5722 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6001 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5620 - binary_accuracy: 0.770 - ETA: 0s - loss: 0.5575 - binary_accuracy: 0.757 - ETA: 0s - loss: 0.5385 - binary_accuracy: 0.768 - ETA: 0s - loss: 0.5540 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5642 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5577 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.6130 - binary_accuracy: 0.712 - 1s 2ms/sample - loss: 0.6096 - binary_accuracy: 0.7109\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4674 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5708 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5880 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6143 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6117 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6155 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6125 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6053 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6354 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5697 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5772 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5865 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5925 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5922 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6010 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.5992 - binary_accuracy: 0.6962\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5654 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5779 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5673 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5724 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5737 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5804 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5951 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5921 - binary_accuracy: 0.7021\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.7093 - binary_accuracy: 0.46 - ETA: 19s - loss: 0.7050 - binary_accuracy: 0.45 - ETA: 11s - loss: 0.6975 - binary_accuracy: 0.45 - ETA: 7s - loss: 0.6824 - binary_accuracy: 0.5469 - ETA: 5s - loss: 0.6632 - binary_accuracy: 0.593 - ETA: 3s - loss: 0.6440 - binary_accuracy: 0.625 - ETA: 2s - loss: 0.6397 - binary_accuracy: 0.638 - ETA: 1s - loss: 0.6556 - binary_accuracy: 0.636 - ETA: 0s - loss: 0.6541 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6424 - binary_accuracy: 0.659 - 5s 15ms/sample - loss: 0.6528 - binary_accuracy: 0.6519\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5612 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6093 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6178 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6243 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6258 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.678 - 1s 2ms/sample - loss: 0.6243 - binary_accuracy: 0.6814\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6141 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6171 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6080 - binary_accuracy: 0.6903\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5721 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5936 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5966 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6132 - binary_accuracy: 0.6785\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6667 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5787 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5817 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6038 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6173 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6254 - binary_accuracy: 0.659 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.665 - 1s 2ms/sample - loss: 0.6184 - binary_accuracy: 0.6667\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5676 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5808 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6059 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5954 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5957 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5940 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5194 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5788 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5770 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5739 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5786 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6031 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5877 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.700 - 1s 2ms/sample - loss: 0.6006 - binary_accuracy: 0.7021\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6784 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6516 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6291 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6043 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5915 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.5947 - binary_accuracy: 0.6932\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6261 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5779 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5745 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5786 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.690 - 1s 2ms/sample - loss: 0.6047 - binary_accuracy: 0.6814\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5726 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5901 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6169 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6120 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5947 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5982 - binary_accuracy: 0.6962\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4684 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.4861 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5243 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5753 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5798 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5863 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5856 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5811 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5758 - binary_accuracy: 0.712 - 1s 2ms/sample - loss: 0.5896 - binary_accuracy: 0.6962\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5913 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6205 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5981 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6063 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5894 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.5844 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.5909 - binary_accuracy: 0.6873\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 41s - loss: 0.7033 - binary_accuracy: 0.56 - ETA: 18s - loss: 0.6577 - binary_accuracy: 0.64 - ETA: 11s - loss: 0.6388 - binary_accuracy: 0.66 - ETA: 7s - loss: 0.6497 - binary_accuracy: 0.6641 - ETA: 5s - loss: 0.6627 - binary_accuracy: 0.656 - ETA: 3s - loss: 0.6506 - binary_accuracy: 0.666 - ETA: 2s - loss: 0.6279 - binary_accuracy: 0.692 - ETA: 1s - loss: 0.6382 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6403 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6454 - binary_accuracy: 0.671 - 5s 15ms/sample - loss: 0.6416 - binary_accuracy: 0.6755\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5762 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5600 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5665 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5887 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5889 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5900 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6004 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6069 - binary_accuracy: 0.6932\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.5542 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5700 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.5856 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6141 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6233 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.668 - 1s 2ms/sample - loss: 0.6107 - binary_accuracy: 0.6726\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7397 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.7150 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.7277 - binary_accuracy: 0.572 - ETA: 0s - loss: 0.6951 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6617 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6360 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6291 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6190 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6244 - binary_accuracy: 0.6903\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6703 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6055 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6119 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6113 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6167 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6016 - binary_accuracy: 0.6932\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6173 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6544 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6321 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6305 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.5926 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6211 - binary_accuracy: 0.636 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6093 - binary_accuracy: 0.656 - 1s 2ms/sample - loss: 0.6048 - binary_accuracy: 0.6608\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5167 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5191 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5531 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5740 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5821 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5789 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5915 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.5938 - binary_accuracy: 0.6991\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7031 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6715 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6606 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6248 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6243 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6048 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.5918 - binary_accuracy: 0.6991\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6326 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6004 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5721 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5725 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5790 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.6231 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5944 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6021 - binary_accuracy: 0.6962\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7057 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6613 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6177 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6147 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6106 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6054 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.712 - 1s 2ms/sample - loss: 0.5992 - binary_accuracy: 0.7139\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5490 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5593 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5686 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5594 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5635 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5787 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5935 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6015 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.5989 - binary_accuracy: 0.6873\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5461 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5928 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5953 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5947 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5862 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5824 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5832 - binary_accuracy: 0.718 - 1s 2ms/sample - loss: 0.5908 - binary_accuracy: 0.7080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 44fda8a2b5d14c286b50e325a2ee6147</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7089478969573975</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 44s - loss: 0.6692 - binary_accuracy: 0.59 - ETA: 20s - loss: 0.6054 - binary_accuracy: 0.70 - ETA: 11s - loss: 0.5957 - binary_accuracy: 0.71 - ETA: 7s - loss: 0.6307 - binary_accuracy: 0.7031 - ETA: 5s - loss: 0.6631 - binary_accuracy: 0.687 - ETA: 3s - loss: 0.6589 - binary_accuracy: 0.687 - ETA: 2s - loss: 0.6469 - binary_accuracy: 0.696 - ETA: 1s - loss: 0.6400 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6466 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6508 - binary_accuracy: 0.675 - 5s 16ms/sample - loss: 0.6503 - binary_accuracy: 0.6726\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6547 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6303 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.643 - ETA: 0s - loss: 0.6461 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6461 - binary_accuracy: 0.638 - ETA: 0s - loss: 0.6341 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.665 - 1s 2ms/sample - loss: 0.6216 - binary_accuracy: 0.6726\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5615 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6192 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5995 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5931 - binary_accuracy: 0.723 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.6038 - binary_accuracy: 0.7050\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4569 - binary_accuracy: 0.875 - ETA: 0s - loss: 0.5525 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5844 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5858 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6074 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6023 - binary_accuracy: 0.6873\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6636 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6028 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6117 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5941 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5920 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6033 - binary_accuracy: 0.6932\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6530 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6112 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6114 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6138 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.675 - 1s 2ms/sample - loss: 0.5893 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6895 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.7404 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6402 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6317 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6265 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6162 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6119 - binary_accuracy: 0.6962\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5823 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.5859 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6053 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5954 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5898 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5944 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5932 - binary_accuracy: 0.7050\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5294 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5598 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5879 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5705 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5718 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5609 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5724 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5767 - binary_accuracy: 0.721 - 1s 2ms/sample - loss: 0.5783 - binary_accuracy: 0.7168\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6251 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5779 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5954 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5733 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5842 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5878 - binary_accuracy: 0.712 - 1s 2ms/sample - loss: 0.5806 - binary_accuracy: 0.7139\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5782 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5376 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5505 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5792 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5676 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5736 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.5839 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5925 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5873 - binary_accuracy: 0.7021\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6359 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5814 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5990 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6546 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6046 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5907 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5946 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.6005 - binary_accuracy: 0.6962\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 41s - loss: 0.6720 - binary_accuracy: 0.62 - ETA: 18s - loss: 0.6575 - binary_accuracy: 0.64 - ETA: 11s - loss: 0.6191 - binary_accuracy: 0.67 - ETA: 7s - loss: 0.6916 - binary_accuracy: 0.6172 - ETA: 5s - loss: 0.6672 - binary_accuracy: 0.637 - ETA: 3s - loss: 0.6533 - binary_accuracy: 0.645 - ETA: 2s - loss: 0.6513 - binary_accuracy: 0.642 - ETA: 1s - loss: 0.6394 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6399 - binary_accuracy: 0.665 - 5s 15ms/sample - loss: 0.6382 - binary_accuracy: 0.6667\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5669 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5292 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5489 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.6201 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6005 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5914 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.6041 - binary_accuracy: 0.6873\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5880 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5755 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5877 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6047 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6080 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.5933 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5896 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6216 - binary_accuracy: 0.6755\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7077 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6244 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6309 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6241 - binary_accuracy: 0.6785\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5341 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5716 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5416 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5165 - binary_accuracy: 0.773 - ETA: 0s - loss: 0.5578 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5833 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5769 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5937 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.6175 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6135 - binary_accuracy: 0.6962\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6997 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6300 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6323 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6220 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6323 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6248 - binary_accuracy: 0.6726\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5917 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5666 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5846 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5843 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.709 - 1s 2ms/sample - loss: 0.5901 - binary_accuracy: 0.7021\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6560 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6684 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6424 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6076 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5991 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6007 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6000 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.5964 - binary_accuracy: 0.6991\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6320 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6388 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6040 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6073 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6213 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.700 - 1s 2ms/sample - loss: 0.5929 - binary_accuracy: 0.7109\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6410 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6490 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5969 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5833 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5794 - binary_accuracy: 0.721 - 1s 2ms/sample - loss: 0.5906 - binary_accuracy: 0.7109\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6622 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5674 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5509 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5732 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5660 - binary_accuracy: 0.762 - ETA: 0s - loss: 0.5823 - binary_accuracy: 0.744 - ETA: 0s - loss: 0.5926 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.715 - 1s 2ms/sample - loss: 0.5963 - binary_accuracy: 0.7198\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5355 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5662 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5873 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6204 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.703 - 1s 2ms/sample - loss: 0.5983 - binary_accuracy: 0.7050\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.7443 - binary_accuracy: 0.34 - ETA: 19s - loss: 0.6655 - binary_accuracy: 0.54 - ETA: 11s - loss: 0.6711 - binary_accuracy: 0.57 - ETA: 7s - loss: 0.6373 - binary_accuracy: 0.6172 - ETA: 5s - loss: 0.6578 - binary_accuracy: 0.618 - ETA: 3s - loss: 0.6565 - binary_accuracy: 0.625 - ETA: 2s - loss: 0.6611 - binary_accuracy: 0.629 - ETA: 1s - loss: 0.6548 - binary_accuracy: 0.636 - ETA: 0s - loss: 0.6440 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6471 - binary_accuracy: 0.656 - 5s 15ms/sample - loss: 0.6505 - binary_accuracy: 0.6431\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6544 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6236 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6213 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6108 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6036 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5899 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.700 - 1s 2ms/sample - loss: 0.6241 - binary_accuracy: 0.6873\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5974 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6109 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6093 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6124 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6151 - binary_accuracy: 0.6873\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6547 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6296 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.669 - ETA: 0s - loss: 0.6121 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6072 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6024 - binary_accuracy: 0.6903\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5919 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6172 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6491 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6883 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6518 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6470 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6337 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6275 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6222 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.696 - 1s 2ms/sample - loss: 0.6096 - binary_accuracy: 0.6932\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5790 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6261 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6055 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.5817 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6033 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6194 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6059 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.684 - 1s 2ms/sample - loss: 0.6109 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5937 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5935 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5970 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5888 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5864 - binary_accuracy: 0.706 - 1s 2ms/sample - loss: 0.5811 - binary_accuracy: 0.7109\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6969 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.5740 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5825 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5672 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6252 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6323 - binary_accuracy: 0.642 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.681 - 1s 2ms/sample - loss: 0.6066 - binary_accuracy: 0.6873\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5711 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5515 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5507 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5395 - binary_accuracy: 0.757 - ETA: 0s - loss: 0.5389 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5557 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5852 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5956 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6141 - binary_accuracy: 0.687 - 1s 2ms/sample - loss: 0.6132 - binary_accuracy: 0.6903\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5058 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5448 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5515 - binary_accuracy: 0.791 - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6126 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6122 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.718 - 1s 2ms/sample - loss: 0.6007 - binary_accuracy: 0.7139\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4942 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5224 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5625 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5652 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5949 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6011 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5928 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5854 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.693 - 1s 2ms/sample - loss: 0.5929 - binary_accuracy: 0.6932\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5157 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5251 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.4938 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5299 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5170 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5032 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5143 - binary_accuracy: 0.763 - ETA: 0s - loss: 0.5483 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5550 - binary_accuracy: 0.736 - ETA: 0s - loss: 0.5763 - binary_accuracy: 0.712 - 1s 2ms/sample - loss: 0.5936 - binary_accuracy: 0.7021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: f6ee67372d882dd5bf227f226c24a685</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7168142199516296</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 160</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 45s - loss: 0.6828 - binary_accuracy: 0.56 - ETA: 20s - loss: 1.0268 - binary_accuracy: 0.65 - ETA: 12s - loss: 1.5573 - binary_accuracy: 0.55 - ETA: 8s - loss: 1.3388 - binary_accuracy: 0.5625 - ETA: 5s - loss: 1.2081 - binary_accuracy: 0.575 - ETA: 4s - loss: 1.0977 - binary_accuracy: 0.609 - ETA: 2s - loss: 1.0244 - binary_accuracy: 0.625 - ETA: 1s - loss: 0.9906 - binary_accuracy: 0.617 - ETA: 0s - loss: 0.9443 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.9050 - binary_accuracy: 0.646 - 6s 17ms/sample - loss: 0.8917 - binary_accuracy: 0.6460\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6508 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6611 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6507 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6463 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6463 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6257 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6312 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6568 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6663 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6722 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6660 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6679 - binary_accuracy: 0.631 - ETA: 0s - loss: 0.6711 - binary_accuracy: 0.619 - ETA: 0s - loss: 0.6693 - binary_accuracy: 0.629 - ETA: 0s - loss: 0.6632 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6561 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6511 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6509 - binary_accuracy: 0.6785\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6484 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6107 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6530 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6629 - binary_accuracy: 0.650 - ETA: 0s - loss: 0.6756 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6594 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6355 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6271 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6318 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6057 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6288 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6302 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6297 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6423 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6312 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6277 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6561 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6710 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6678 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6595 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6454 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6427 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6407 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6300 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6283 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6532 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5809 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6376 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6420 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6475 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6425 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6357 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6406 - binary_accuracy: 0.671 - 1s 3ms/sample - loss: 0.6315 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6513 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6267 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6764 - binary_accuracy: 0.614 - ETA: 0s - loss: 0.6471 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6297 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7308 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6736 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6493 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6539 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6367 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6258 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6159 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6228 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6251 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6119 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6608 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6533 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6475 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6604 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.638 - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6378 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6325 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6411 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6388 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6429 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6392 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6386 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6349 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6259 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6228 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7110 - binary_accuracy: 0.562 - ETA: 0s - loss: 0.6763 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6833 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.6970 - binary_accuracy: 0.585 - ETA: 0s - loss: 0.6811 - binary_accuracy: 0.606 - ETA: 0s - loss: 0.6606 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6496 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6195 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6275 - binary_accuracy: 0.6844\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 40s - loss: 0.6999 - binary_accuracy: 0.37 - ETA: 18s - loss: 1.0784 - binary_accuracy: 0.54 - ETA: 11s - loss: 1.5397 - binary_accuracy: 0.47 - ETA: 7s - loss: 1.3868 - binary_accuracy: 0.5312 - ETA: 5s - loss: 1.2725 - binary_accuracy: 0.500 - ETA: 3s - loss: 1.1521 - binary_accuracy: 0.546 - ETA: 2s - loss: 1.0900 - binary_accuracy: 0.562 - ETA: 1s - loss: 1.0225 - binary_accuracy: 0.589 - ETA: 0s - loss: 0.9901 - binary_accuracy: 0.590 - ETA: 0s - loss: 0.9563 - binary_accuracy: 0.593 - 5s 15ms/sample - loss: 0.9400 - binary_accuracy: 0.5929\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6412 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6735 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6383 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6181 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6568 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6504 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6449 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6539 - binary_accuracy: 0.671 - 1s 3ms/sample - loss: 0.6474 - binary_accuracy: 0.6814\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5670 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6496 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6427 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6165 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5625 - binary_accuracy: 0.770 - ETA: 0s - loss: 0.5869 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.6396 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6514 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6617 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5592 - binary_accuracy: 0.796 - ETA: 0s - loss: 0.5801 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.6103 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6154 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6267 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6263 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6860 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6346 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6521 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6646 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6658 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6531 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6520 - binary_accuracy: 0.647 - ETA: 0s - loss: 0.6434 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6294 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6238 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6267 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6781 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6629 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6068 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6178 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6169 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6259 - binary_accuracy: 0.6844\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6999 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6995 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6366 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6342 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6354 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6281 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6243 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6261 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6498 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6682 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.7024 - binary_accuracy: 0.583 - ETA: 0s - loss: 0.6854 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6648 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6470 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6301 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6364 - binary_accuracy: 0.675 - 1s 3ms/sample - loss: 0.6284 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6065 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6219 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6050 - binary_accuracy: 0.703 - ETA: 1s - loss: 0.6231 - binary_accuracy: 0.687 - ETA: 1s - loss: 0.6297 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6289 - binary_accuracy: 0.683 - ETA: 0s - loss: 0.6220 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.696 - 2s 6ms/sample - loss: 0.6219 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7671 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.6943 - binary_accuracy: 0.593 - ETA: 0s - loss: 0.6554 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6388 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6391 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6438 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6481 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6370 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6315 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6272 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6236 - binary_accuracy: 0.6873\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6639 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6996 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.6595 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6161 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.700 - 1s 3ms/sample - loss: 0.6207 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5785 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5761 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5724 - binary_accuracy: 0.742 - ETA: 0s - loss: 0.5872 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.6127 - binary_accuracy: 0.6962\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 42s - loss: 0.6966 - binary_accuracy: 0.50 - ETA: 19s - loss: 1.1509 - binary_accuracy: 0.59 - ETA: 11s - loss: 1.7058 - binary_accuracy: 0.50 - ETA: 7s - loss: 1.4824 - binary_accuracy: 0.5469 - ETA: 5s - loss: 1.3076 - binary_accuracy: 0.600 - ETA: 3s - loss: 1.1839 - binary_accuracy: 0.625 - ETA: 2s - loss: 1.1184 - binary_accuracy: 0.629 - ETA: 1s - loss: 1.0493 - binary_accuracy: 0.644 - ETA: 0s - loss: 0.9982 - binary_accuracy: 0.652 - ETA: 0s - loss: 0.9674 - binary_accuracy: 0.646 - 5s 16ms/sample - loss: 0.9534 - binary_accuracy: 0.6401\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6484 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6353 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6256 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6390 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6271 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6335 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6466 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5657 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5873 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6128 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6220 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6194 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6283 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6248 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6227 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6291 - binary_accuracy: 0.6844\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6362 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6576 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6398 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6316 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6354 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6303 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6253 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6252 - binary_accuracy: 0.6844\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5990 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.718 - ETA: 1s - loss: 0.5787 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6089 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6189 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6356 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6250 - binary_accuracy: 0.690 - 1s 4ms/sample - loss: 0.6292 - binary_accuracy: 0.6844\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.8608 - binary_accuracy: 0.375 - ETA: 0s - loss: 0.7663 - binary_accuracy: 0.500 - ETA: 0s - loss: 0.7065 - binary_accuracy: 0.604 - ETA: 0s - loss: 0.7009 - binary_accuracy: 0.601 - ETA: 0s - loss: 0.6805 - binary_accuracy: 0.637 - ETA: 0s - loss: 0.6669 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6698 - binary_accuracy: 0.651 - ETA: 0s - loss: 0.6705 - binary_accuracy: 0.644 - ETA: 0s - loss: 0.6621 - binary_accuracy: 0.659 - ETA: 0s - loss: 0.6572 - binary_accuracy: 0.668 - 1s 4ms/sample - loss: 0.6496 - binary_accuracy: 0.6814\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5955 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6419 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6147 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6427 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6409 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6389 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6304 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6423 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6351 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6351 - binary_accuracy: 0.6844\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5700 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5851 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5862 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5814 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5869 - binary_accuracy: 0.724 - ETA: 0s - loss: 0.5912 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6018 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6217 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6213 - binary_accuracy: 0.6844\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6620 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6702 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6313 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6355 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6348 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6351 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6246 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6240 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6271 - binary_accuracy: 0.6844\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5728 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.6430 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6550 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6483 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6032 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6131 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6117 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.687 - 1s 3ms/sample - loss: 0.6247 - binary_accuracy: 0.6844\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6787 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6638 - binary_accuracy: 0.640 - ETA: 0s - loss: 0.6710 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6693 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.6426 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6308 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6247 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6334 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6225 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6306 - binary_accuracy: 0.678 - 1s 3ms/sample - loss: 0.6257 - binary_accuracy: 0.6844\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6066 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6292 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6310 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6211 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6092 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6197 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6258 - binary_accuracy: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 19fe3ebd77dbb70ce0047d52bbc7d27e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6882989406585693</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 47s - loss: 0.7138 - binary_accuracy: 0.46 - ETA: 21s - loss: 0.6486 - binary_accuracy: 0.64 - ETA: 13s - loss: 0.6875 - binary_accuracy: 0.64 - ETA: 8s - loss: 0.6272 - binary_accuracy: 0.6953 - ETA: 6s - loss: 0.6416 - binary_accuracy: 0.687 - ETA: 4s - loss: 0.6387 - binary_accuracy: 0.687 - ETA: 2s - loss: 0.6401 - binary_accuracy: 0.683 - ETA: 1s - loss: 0.6445 - binary_accuracy: 0.664 - ETA: 1s - loss: 0.6510 - binary_accuracy: 0.638 - ETA: 0s - loss: 0.6554 - binary_accuracy: 0.625 - 6s 18ms/sample - loss: 0.6533 - binary_accuracy: 0.6313\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.7644 - binary_accuracy: 0.578 - ETA: 0s - loss: 0.7100 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.7017 - binary_accuracy: 0.632 - ETA: 0s - loss: 0.7001 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6808 - binary_accuracy: 0.645 - ETA: 0s - loss: 0.6660 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6632 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6539 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6416 - binary_accuracy: 0.6844\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5786 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5273 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6203 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6281 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.682 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.673 - ETA: 0s - loss: 0.6284 - binary_accuracy: 0.668 - 1s 3ms/sample - loss: 0.6256 - binary_accuracy: 0.6726\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6465 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6333 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6219 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6222 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6117 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6059 - binary_accuracy: 0.684 - 1s 4ms/sample - loss: 0.5963 - binary_accuracy: 0.6903\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5456 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6509 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6258 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6201 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6373 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6320 - binary_accuracy: 0.665 - ETA: 0s - loss: 0.6285 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6142 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6127 - binary_accuracy: 0.6814\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5151 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6168 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6255 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5877 - binary_accuracy: 0.706 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6076 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6127 - binary_accuracy: 0.680 - ETA: 0s - loss: 0.6115 - binary_accuracy: 0.681 - 1s 4ms/sample - loss: 0.6056 - binary_accuracy: 0.6962\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.4901 - binary_accuracy: 0.875 - ETA: 0s - loss: 0.4733 - binary_accuracy: 0.875 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6270 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6265 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6144 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6051 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6031 - binary_accuracy: 0.706 - 1s 4ms/sample - loss: 0.6068 - binary_accuracy: 0.7050\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6505 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5782 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5975 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.6062 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.6148 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.6009 - binary_accuracy: 0.6932\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6505 - binary_accuracy: 0.625 - ETA: 1s - loss: 0.5975 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5741 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5860 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.5910 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5896 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5983 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.5932 - binary_accuracy: 0.6962\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.7447 - binary_accuracy: 0.468 - ETA: 0s - loss: 0.6528 - binary_accuracy: 0.609 - ETA: 0s - loss: 0.6400 - binary_accuracy: 0.635 - ETA: 0s - loss: 0.6363 - binary_accuracy: 0.648 - ETA: 0s - loss: 0.6183 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6180 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.660 - ETA: 0s - loss: 0.6176 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6045 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.5957 - binary_accuracy: 0.6962\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6089 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5391 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5296 - binary_accuracy: 0.760 - ETA: 0s - loss: 0.5331 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5346 - binary_accuracy: 0.762 - ETA: 0s - loss: 0.5780 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5870 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5913 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6026 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5930 - binary_accuracy: 0.709 - 1s 4ms/sample - loss: 0.5926 - binary_accuracy: 0.7109\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6332 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6151 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5850 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.706 - 1s 3ms/sample - loss: 0.5984 - binary_accuracy: 0.7109\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 52s - loss: 0.6921 - binary_accuracy: 0.53 - ETA: 23s - loss: 0.7113 - binary_accuracy: 0.53 - ETA: 14s - loss: 0.6946 - binary_accuracy: 0.57 - ETA: 9s - loss: 0.6601 - binary_accuracy: 0.6328 - ETA: 6s - loss: 0.6884 - binary_accuracy: 0.631 - ETA: 4s - loss: 0.6767 - binary_accuracy: 0.640 - ETA: 3s - loss: 0.6658 - binary_accuracy: 0.638 - ETA: 2s - loss: 0.6458 - binary_accuracy: 0.656 - ETA: 1s - loss: 0.6378 - binary_accuracy: 0.663 - ETA: 0s - loss: 0.6464 - binary_accuracy: 0.653 - 7s 20ms/sample - loss: 0.6453 - binary_accuracy: 0.6608\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5958 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5768 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5553 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5350 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5923 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6149 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.6075 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6146 - binary_accuracy: 0.678 - 1s 4ms/sample - loss: 0.6145 - binary_accuracy: 0.6814\n",
      "Epoch 3/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6178 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5964 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5831 - binary_accuracy: 0.727 - ETA: 0s - loss: 0.5875 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.6060 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.721 - 1s 3ms/sample - loss: 0.6141 - binary_accuracy: 0.7080\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5192 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5059 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.5703 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5741 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5758 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5900 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5973 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.6056 - binary_accuracy: 0.7021\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5683 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5393 - binary_accuracy: 0.765 - ETA: 0s - loss: 0.5562 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5736 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5557 - binary_accuracy: 0.743 - ETA: 0s - loss: 0.5709 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5902 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5926 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5920 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5925 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.5974 - binary_accuracy: 0.7139\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5565 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5783 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6215 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6340 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6168 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6078 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5881 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.722 - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.718 - 1s 3ms/sample - loss: 0.5999 - binary_accuracy: 0.7139\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6817 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6053 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5915 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5743 - binary_accuracy: 0.737 - ETA: 0s - loss: 0.5766 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6001 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5889 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.712 - 1s 3ms/sample - loss: 0.5955 - binary_accuracy: 0.7109\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5921 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5810 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5949 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5982 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5917 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.5947 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.5917 - binary_accuracy: 0.6991\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4990 - binary_accuracy: 0.843 - ETA: 0s - loss: 0.5232 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6077 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6123 - binary_accuracy: 0.696 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5901 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5902 - binary_accuracy: 0.712 - 1s 3ms/sample - loss: 0.5949 - binary_accuracy: 0.7080\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.6281 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6273 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6262 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.6094 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.6377 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6174 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6003 - binary_accuracy: 0.701 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.693 - 1s 4ms/sample - loss: 0.5993 - binary_accuracy: 0.6991\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5516 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5929 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6182 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5989 - binary_accuracy: 0.668 - ETA: 0s - loss: 0.6201 - binary_accuracy: 0.661 - ETA: 0s - loss: 0.6185 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6269 - binary_accuracy: 0.649 - ETA: 0s - loss: 0.6280 - binary_accuracy: 0.646 - 1s 3ms/sample - loss: 0.6273 - binary_accuracy: 0.6490\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5489 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6236 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5903 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6002 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6058 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.6079 - binary_accuracy: 0.705 - ETA: 0s - loss: 0.5971 - binary_accuracy: 0.707 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5938 - binary_accuracy: 0.706 - 1s 3ms/sample - loss: 0.5949 - binary_accuracy: 0.7050\n",
      "Train on 339 samples\n",
      "Epoch 1/12\n",
      "339/339 [==============================] - ETA: 47s - loss: 0.6921 - binary_accuracy: 0.53 - ETA: 21s - loss: 0.6249 - binary_accuracy: 0.64 - ETA: 13s - loss: 0.6797 - binary_accuracy: 0.64 - ETA: 9s - loss: 0.7212 - binary_accuracy: 0.6094 - ETA: 6s - loss: 0.7040 - binary_accuracy: 0.625 - ETA: 4s - loss: 0.7061 - binary_accuracy: 0.578 - ETA: 2s - loss: 0.7108 - binary_accuracy: 0.558 - ETA: 1s - loss: 0.7071 - binary_accuracy: 0.546 - ETA: 1s - loss: 0.7029 - binary_accuracy: 0.555 - ETA: 0s - loss: 0.6904 - binary_accuracy: 0.578 - 6s 18ms/sample - loss: 0.6782 - binary_accuracy: 0.5929\n",
      "Epoch 2/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5832 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6441 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6610 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6557 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6719 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6584 - binary_accuracy: 0.674 - ETA: 0s - loss: 0.6437 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6395 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6388 - binary_accuracy: 0.690 - 1s 3ms/sample - loss: 0.6380 - binary_accuracy: 0.6873\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 1s - loss: 0.6104 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.6167 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6097 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5937 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.675 - ETA: 0s - loss: 0.6193 - binary_accuracy: 0.670 - ETA: 0s - loss: 0.6081 - binary_accuracy: 0.681 - 1s 3ms/sample - loss: 0.6150 - binary_accuracy: 0.6755\n",
      "Epoch 4/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5588 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5553 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5849 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5946 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6025 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6019 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.6012 - binary_accuracy: 0.711 - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.715 - 1s 3ms/sample - loss: 0.5992 - binary_accuracy: 0.7139\n",
      "Epoch 5/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5338 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5725 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5954 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.6041 - binary_accuracy: 0.712 - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.697 - ETA: 0s - loss: 0.5980 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5864 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.704 - ETA: 0s - loss: 0.6049 - binary_accuracy: 0.703 - 1s 3ms/sample - loss: 0.6018 - binary_accuracy: 0.7050\n",
      "Epoch 6/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6110 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.5908 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6648 - binary_accuracy: 0.625 - ETA: 0s - loss: 0.6331 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6271 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.666 - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.678 - ETA: 0s - loss: 0.6128 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.684 - ETA: 0s - loss: 0.6061 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6054 - binary_accuracy: 0.6814\n",
      "Epoch 7/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5232 - binary_accuracy: 0.812 - ETA: 0s - loss: 0.6075 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5967 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.6021 - binary_accuracy: 0.710 - ETA: 0s - loss: 0.5878 - binary_accuracy: 0.725 - ETA: 0s - loss: 0.5736 - binary_accuracy: 0.734 - ETA: 0s - loss: 0.5810 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5883 - binary_accuracy: 0.708 - ETA: 0s - loss: 0.5951 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.5991 - binary_accuracy: 0.6903\n",
      "Epoch 8/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.6742 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6441 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6609 - binary_accuracy: 0.677 - ETA: 0s - loss: 0.6653 - binary_accuracy: 0.664 - ETA: 0s - loss: 0.6526 - binary_accuracy: 0.662 - ETA: 0s - loss: 0.6360 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.6241 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.6209 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.684 - 1s 3ms/sample - loss: 0.6238 - binary_accuracy: 0.6873\n",
      "Epoch 9/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5048 - binary_accuracy: 0.781 - ETA: 0s - loss: 0.5403 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.5353 - binary_accuracy: 0.739 - ETA: 0s - loss: 0.5574 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5529 - binary_accuracy: 0.731 - ETA: 0s - loss: 0.5852 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5895 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5988 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5958 - binary_accuracy: 0.696 - 1s 3ms/sample - loss: 0.5964 - binary_accuracy: 0.7021\n",
      "Epoch 10/12\n",
      "339/339 [==============================] - ETA: 1s - loss: 0.5962 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.6052 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.6160 - binary_accuracy: 0.679 - ETA: 0s - loss: 0.6158 - binary_accuracy: 0.681 - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.5994 - binary_accuracy: 0.692 - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5970 - binary_accuracy: 0.691 - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.693 - 1s 3ms/sample - loss: 0.5922 - binary_accuracy: 0.7021\n",
      "Epoch 11/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5354 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5326 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5669 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5639 - binary_accuracy: 0.726 - ETA: 0s - loss: 0.5797 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.729 - ETA: 0s - loss: 0.5796 - binary_accuracy: 0.732 - ETA: 0s - loss: 0.5897 - binary_accuracy: 0.714 - ETA: 0s - loss: 0.5910 - binary_accuracy: 0.715 - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.718 - 1s 4ms/sample - loss: 0.5903 - binary_accuracy: 0.7168\n",
      "Epoch 12/12\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.5214 - binary_accuracy: 0.750 - ETA: 0s - loss: 0.6044 - binary_accuracy: 0.671 - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.687 - ETA: 0s - loss: 0.5702 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5970 - binary_accuracy: 0.693 - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.703 - ETA: 0s - loss: 0.5809 - binary_accuracy: 0.709 - ETA: 0s - loss: 0.5942 - binary_accuracy: 0.695 - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.718 - ETA: 0s - loss: 0.5761 - binary_accuracy: 0.718 - 1s 3ms/sample - loss: 0.5810 - binary_accuracy: 0.7168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 708db1a588eac14fdbef22113192886f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7138643264770508</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='binary_accuracy',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    allow_new_entries=True)\n",
    "\n",
    "tuner.search_space_summary()\n",
    "tuner.search(X_buy_train, y_buy_train, epochs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in ./untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='binary_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9cd8274ff80d741bd254c1b217e444f9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7207472920417786</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c8c1ef4527c5833d32e68f7f9956ddd7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7187807559967041</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: efc70869a7d78c6ee79c9e9e295f8923</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7177974581718445</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: f6ee67372d882dd5bf227f226c24a685</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7168142199516296</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 160</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 72289c8df8680aff6ca457005c6e8bfc</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7138643264770508</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 708db1a588eac14fdbef22113192886f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7138643264770508</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 44fda8a2b5d14c286b50e325a2ee6147</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7089478969573975</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 0b4b056a342d5badf1e787bd85b6b93a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7059980034828186</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c4a79a8be6e11431f417f0bcd54008b7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7050147652626038</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 713f054fd6c339f89c7a603559fd6441</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7040314674377441</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 96)            86784     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 96)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 96)            74112     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 96)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 96)                74112     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 235,105\n",
      "Trainable params: 235,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Analyzing 85 samples\n",
      "Threshold: 0.65\n",
      "False Negative, prob: 0.43819788098335266\n",
      "False Negative, prob: 0.6266543865203857\n",
      "False Negative, prob: 0.33854687213897705\n",
      "False Negative, prob: 0.24066075682640076\n",
      "False Negative, prob: 0.32920220494270325\n",
      "Profit: -103\n",
      "Profit: 128\n",
      "False Negative, prob: 0.16294510662555695\n",
      "Profit: 124\n",
      "Profit: -239\n",
      "Profit: -387\n",
      "Profit: -269\n",
      "False Negative, prob: 0.3520950675010681\n",
      "False Negative, prob: 0.3475078046321869\n",
      "False Negative, prob: 0.1644393652677536\n",
      "False Negative, prob: 0.16497287154197693\n",
      "False Negative, prob: 0.3605259954929352\n",
      "False Negative, prob: 0.2913254201412201\n",
      "False Negative, prob: 0.44736728072166443\n",
      "False Negative, prob: 0.39335983991622925\n",
      "False Negative, prob: 0.17435835301876068\n",
      "False Negative, prob: 0.20695777237415314\n",
      "False Negative, prob: 0.2973286211490631\n",
      "False Negative, prob: 0.5394469499588013\n",
      "False Negative, prob: 0.19595956802368164\n",
      "False Negative, prob: 0.616627037525177\n",
      "False Negative, prob: 0.37011829018592834\n",
      "False Negative, prob: 0.295245498418808\n",
      "The model guessed:\n",
      "\t2/24 profitable trades correctly (true positives)\n",
      "\t22/24 profitable trades incorrectly (false negatives)\n",
      "\t57/61 unprofitable trades correctly (true negatives)\n",
      "\t4/61 unprofitable trades incorrectly (false positives)\n",
      "\t Precision: 0.3333333333333333\n",
      "\t Recall: 0.08333333333333333\n",
      "\t Profit: -746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 0.08333333333333333)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n",
    "precision_recall(best_model, X_buy_test, y_buy_test, profit_buy_test, threshold=0.65)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 75)                62700     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 76        \n",
      "=================================================================\n",
      "Total params: 62,776\n",
      "Trainable params: 62,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 418 samples\n",
      "Epoch 1/32\n",
      "418/418 - 5s - loss: 0.6714 - accuracy: 0.6100\n",
      "Epoch 2/32\n",
      "418/418 - 3s - loss: 0.6506 - accuracy: 0.6459\n",
      "Epoch 3/32\n",
      "418/418 - 3s - loss: 0.6521 - accuracy: 0.6340\n",
      "Epoch 4/32\n",
      "418/418 - 3s - loss: 0.6281 - accuracy: 0.6603\n",
      "Epoch 5/32\n",
      "418/418 - 3s - loss: 0.6285 - accuracy: 0.6603\n",
      "Epoch 6/32\n",
      "418/418 - 3s - loss: 0.6225 - accuracy: 0.6794\n",
      "Epoch 7/32\n",
      "418/418 - 3s - loss: 0.6212 - accuracy: 0.6914\n",
      "Epoch 8/32\n",
      "418/418 - 3s - loss: 0.6209 - accuracy: 0.6746\n",
      "Epoch 9/32\n",
      "418/418 - 3s - loss: 0.6218 - accuracy: 0.6699\n",
      "Epoch 10/32\n",
      "418/418 - 3s - loss: 0.6133 - accuracy: 0.6722\n",
      "Epoch 11/32\n",
      "418/418 - 3s - loss: 0.6052 - accuracy: 0.6794\n",
      "Epoch 12/32\n",
      "418/418 - 3s - loss: 0.5996 - accuracy: 0.6986\n",
      "Epoch 13/32\n",
      "418/418 - 3s - loss: 0.6045 - accuracy: 0.6627\n",
      "Epoch 14/32\n",
      "418/418 - 3s - loss: 0.6037 - accuracy: 0.6770\n",
      "Epoch 15/32\n",
      "418/418 - 3s - loss: 0.5939 - accuracy: 0.6890\n",
      "Epoch 16/32\n",
      "418/418 - 3s - loss: 0.6038 - accuracy: 0.6938\n",
      "Epoch 17/32\n",
      "418/418 - 3s - loss: 0.5802 - accuracy: 0.7033\n",
      "Epoch 18/32\n",
      "418/418 - 3s - loss: 0.5820 - accuracy: 0.7033\n",
      "Epoch 19/32\n",
      "418/418 - 3s - loss: 0.5759 - accuracy: 0.6914\n",
      "Epoch 20/32\n",
      "418/418 - 3s - loss: 0.5837 - accuracy: 0.7153\n",
      "Epoch 21/32\n",
      "418/418 - 3s - loss: 0.5756 - accuracy: 0.7010\n",
      "Epoch 22/32\n",
      "418/418 - 3s - loss: 0.5595 - accuracy: 0.7081\n",
      "Epoch 23/32\n",
      "418/418 - 3s - loss: 0.5711 - accuracy: 0.7010\n",
      "Epoch 24/32\n",
      "418/418 - 3s - loss: 0.5626 - accuracy: 0.6962\n",
      "Epoch 25/32\n",
      "418/418 - 3s - loss: 0.5551 - accuracy: 0.7105\n",
      "Epoch 26/32\n",
      "418/418 - 3s - loss: 0.5385 - accuracy: 0.7273\n",
      "Epoch 27/32\n",
      "418/418 - 3s - loss: 0.5465 - accuracy: 0.7321\n",
      "Epoch 28/32\n",
      "418/418 - 3s - loss: 0.5458 - accuracy: 0.7344\n",
      "Epoch 29/32\n",
      "418/418 - 3s - loss: 0.5203 - accuracy: 0.7440\n",
      "Epoch 30/32\n",
      "418/418 - 3s - loss: 0.5306 - accuracy: 0.7177\n",
      "Epoch 31/32\n",
      "418/418 - 3s - loss: 0.5270 - accuracy: 0.7416\n",
      "Epoch 32/32\n",
      "418/418 - 3s - loss: 0.5411 - accuracy: 0.7321\n",
      "Accuracy: 71.15%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(X_buy_train.shape[1], X_buy_train.shape[2]), dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_buy_train, y_buy_train, epochs=32, batch_size=2, verbose=2, shuffle=True)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test') # Only when using validation set\n",
    "pyplot.legend()\n",
    "\n",
    "scores = model.evaluate(X_buy_test, y_buy_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 104 samples\n",
      "Threshold: 0.4\n",
      "Profit: 1224\n",
      "False Negative, prob: 0.19841518998146057\n",
      "Profit: 1550\n",
      "False Negative, prob: 0.21484872698783875\n",
      "False Negative, prob: 0.26871010661125183\n",
      "Profit: -377\n",
      "Profit: -148\n",
      "Profit: -110\n",
      "False Negative, prob: 0.37544187903404236\n",
      "Profit: -299\n",
      "Profit: -181\n",
      "False Negative, prob: 0.14385874569416046\n",
      "Profit: -785\n",
      "False Negative, prob: 0.33293846249580383\n",
      "Profit: -317\n",
      "False Negative, prob: 0.3717939555644989\n",
      "False Negative, prob: 0.3312969207763672\n",
      "False Negative, prob: 0.3322719931602478\n",
      "False Negative, prob: 0.22167980670928955\n",
      "False Negative, prob: 0.041065674275159836\n",
      "Profit: -233\n",
      "Profit: -222\n",
      "Profit: -334\n",
      "Profit: 492\n",
      "False Negative, prob: 0.13580378890037537\n",
      "Profit: -241\n",
      "False Negative, prob: 0.1874362975358963\n",
      "False Negative, prob: 0.10671545565128326\n",
      "False Negative, prob: 0.1947876513004303\n",
      "False Negative, prob: 0.1374172568321228\n",
      "Profit: -202\n",
      "False Negative, prob: 0.18412047624588013\n",
      "False Negative, prob: 0.30527767539024353\n",
      "Profit: 170\n",
      "Profit: -764\n",
      "Profit: -158\n",
      "False Negative, prob: 0.04308990389108658\n",
      "Profit: 631\n",
      "Profit: -263\n",
      "False Negative, prob: 0.30883297324180603\n",
      "False Negative, prob: 0.1888505071401596\n",
      "Profit: -314\n",
      "Profit: -445\n",
      "Profit: -2354\n",
      "False Negative, prob: 0.035142235457897186\n",
      "Profit: -475\n",
      "The model guessed:\n",
      "\t5/27 profitable trades correctly (true positives)\n",
      "\t22/27 profitable trades incorrectly (false negatives)\n",
      "\t58/77 unprofitable trades correctly (true negatives)\n",
      "\t19/77 unprofitable trades incorrectly (false positives)\n",
      "\t Precision: 0.20833333333333334\n",
      "\t Recall: 0.18518518518518517\n",
      "\t Profit: -4155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20833333333333334, 0.18518518518518517)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall(model, X_buy_test, y_buy_test, profit_buy_test, threshold=0.4)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 10, 100)           93600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 100)           80400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 254,501\n",
      "Trainable params: 254,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 418 samples\n",
      "Epoch 1/12\n",
      "418/418 - 6s - loss: 0.6569 - accuracy: 0.6316\n",
      "Epoch 2/12\n",
      "418/418 - 1s - loss: 0.6402 - accuracy: 0.6483\n",
      "Epoch 3/12\n",
      "418/418 - 1s - loss: 0.6435 - accuracy: 0.6435\n",
      "Epoch 4/12\n",
      "418/418 - 1s - loss: 0.6460 - accuracy: 0.6627\n",
      "Epoch 5/12\n",
      "418/418 - 1s - loss: 0.6473 - accuracy: 0.6531\n",
      "Epoch 6/12\n",
      "418/418 - 1s - loss: 0.6280 - accuracy: 0.6722\n",
      "Epoch 7/12\n",
      "418/418 - 1s - loss: 0.6401 - accuracy: 0.6627\n",
      "Epoch 8/12\n",
      "418/418 - 1s - loss: 0.6428 - accuracy: 0.6316\n",
      "Epoch 9/12\n",
      "418/418 - 1s - loss: 0.6141 - accuracy: 0.6818\n",
      "Epoch 10/12\n",
      "418/418 - 1s - loss: 0.6216 - accuracy: 0.6746\n",
      "Epoch 11/12\n",
      "418/418 - 1s - loss: 0.6134 - accuracy: 0.6794\n",
      "Epoch 12/12\n",
      "418/418 - 1s - loss: 0.6148 - accuracy: 0.6770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f353c3a2828>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(X_buy_train.shape[1], X_buy_train.shape[2]), dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_buy_train, y_buy_train, epochs=12, batch_size=16, verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test') # Only when using validation set\n",
    "pyplot.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.04%\n",
      "Analyzing 104 samples\n",
      "Threshold: 0.5\n",
      "False Negative, prob: 0.28536584973335266\n",
      "False Negative, prob: 0.2250484675168991\n",
      "False Negative, prob: 0.32086339592933655\n",
      "False Negative, prob: 0.2570270597934723\n",
      "False Negative, prob: 0.3253635764122009\n",
      "False Negative, prob: 0.26355549693107605\n",
      "False Negative, prob: 0.3442333936691284\n",
      "False Negative, prob: 0.3148510456085205\n",
      "False Negative, prob: 0.24505846202373505\n",
      "False Negative, prob: 0.31949183344841003\n",
      "False Negative, prob: 0.32762065529823303\n",
      "Profit: 373\n",
      "False Negative, prob: 0.2326124757528305\n",
      "False Negative, prob: 0.3226100206375122\n",
      "False Negative, prob: 0.33607450127601624\n",
      "Profit: -241\n",
      "False Negative, prob: 0.23409084975719452\n",
      "False Negative, prob: 0.2988980710506439\n",
      "False Negative, prob: 0.26833420991897583\n",
      "False Negative, prob: 0.25069698691368103\n",
      "Profit: 631\n",
      "False Negative, prob: 0.3206718862056732\n",
      "False Negative, prob: 0.4092714488506317\n",
      "Profit: -156\n",
      "False Negative, prob: 0.24582023918628693\n",
      "False Negative, prob: 0.309329628944397\n",
      "False Negative, prob: 0.33660200238227844\n",
      "False Negative, prob: 0.33099865913391113\n",
      "False Negative, prob: 0.23115363717079163\n",
      "The model guessed:\n",
      "\t2/27 profitable trades correctly (true positives)\n",
      "\t25/27 profitable trades incorrectly (false negatives)\n",
      "\t75/77 unprofitable trades correctly (true negatives)\n",
      "\t2/77 unprofitable trades incorrectly (false positives)\n",
      "\t Precision: 0.5\n",
      "\t Recall: 0.07407407407407407\n",
      "\t Profit: 607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.07407407407407407)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_buy_test, y_buy_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "precision_recall(model, X_buy_test, y_buy_test, profit_buy_test, threshold=0.5)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM - Non-Padded Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpadded_pipe = Pipeline(\n",
    "            steps=\n",
    "            [\n",
    "                ('min_max',MinMaxer()),\n",
    "                ('transpose', Transposer())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "buy_data_pipelined_non_padded = nonpadded_pipe.transform(buy_inputs)\n",
    "\n",
    "\n",
    "train_perc = 0.8\n",
    "buy_stop_index = round(len(buy_labels) * train_perc)\n",
    "X_buy_train = buy_data_pipelined_non_padded[:buy_stop_index]\n",
    "X_buy_test = buy_data_pipelined_non_padded[buy_stop_index:]\n",
    "y_buy_train = buy_labels[:buy_stop_index]\n",
    "y_buy_test = buy_labels[buy_stop_index:]\n",
    "profit_buy_train = buy_profits[:buy_stop_index]\n",
    "profit_buy_test = buy_profits[buy_stop_index:]\n",
    "\n",
    "print(len(buy_data_pipelined_non_padded[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-3368d68b7d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_buy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(None, X_buy_train.shape[2]), dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_buy_train, y_buy_train, epochs=12, batch_size=16, verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test') # Only when using validation set\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-0bbb047a23b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_buy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_buy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2), input_shape=(X_buy_train.shape[1], X_buy_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_buy_train, y_buy_train, epochs=20, batch_size=16, verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test') # Only when using validation set\n",
    "pyplot.legend()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-7f64dc5ed525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_buy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_buy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprecision_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_buy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_buy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofit_buy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \"\"\"\n\u001b[1;32m    914\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2829\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_buy_test, y_buy_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "precision_recall(model, X_buy_test, y_buy_test, profit_buy_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 10, 200)           181600    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10, 200)           240800    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 663,401\n",
      "Trainable params: 663,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 183 samples\n",
      "Epoch 1/12\n",
      "183/183 - 11s - loss: 0.6694 - accuracy: 0.6885\n",
      "Epoch 2/12\n",
      "183/183 - 1s - loss: 0.6278 - accuracy: 0.6831\n",
      "Epoch 3/12\n",
      "183/183 - 1s - loss: 0.6122 - accuracy: 0.6940\n",
      "Epoch 4/12\n",
      "183/183 - 1s - loss: 0.6145 - accuracy: 0.6940\n",
      "Epoch 5/12\n",
      "183/183 - 1s - loss: 0.6076 - accuracy: 0.7049\n",
      "Epoch 6/12\n",
      "183/183 - 1s - loss: 0.5971 - accuracy: 0.7322\n",
      "Epoch 7/12\n",
      "183/183 - 1s - loss: 0.5838 - accuracy: 0.7377\n",
      "Epoch 8/12\n",
      "183/183 - 1s - loss: 0.5690 - accuracy: 0.7377\n",
      "Epoch 9/12\n",
      "183/183 - 1s - loss: 0.5542 - accuracy: 0.7158\n",
      "Epoch 10/12\n",
      "183/183 - 1s - loss: 0.5329 - accuracy: 0.7596\n",
      "Epoch 11/12\n",
      "183/183 - 1s - loss: 0.5607 - accuracy: 0.7322\n",
      "Epoch 12/12\n",
      "183/183 - 1s - loss: 0.5395 - accuracy: 0.7486\n",
      "Accuracy: 73.91%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True), input_shape=(X_buy_train.shape[1], X_buy_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_buy_train, y_buy_train, epochs=12, batch_size=16, verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test') # Only when using validation set\n",
    "pyplot.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.91%\n",
      "Threshold: 0.5\n",
      "Profit: -170\n",
      "Profit: 201\n",
      "Profit: -161\n",
      "Profit: 861\n",
      "Profit: 269\n",
      "The model guessed:\n",
      "\t3/13 profitable trades correctly (true positives)\n",
      "\t10/13 profitable trades incorrectly (false negatives)\n",
      "\t31/33 unprofitable trades correctly (true negatives)\n",
      "\t2/33 unprofitable trades incorrectly (false positives)\n",
      "\t Precision: 0.6\n",
      "\t Recall: 0.23076923076923078\n",
      "\t Profit: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.23076923076923078)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_buy_test, y_buy_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "precision_recall(model, X_buy_test, y_buy_test, profit_buy_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
